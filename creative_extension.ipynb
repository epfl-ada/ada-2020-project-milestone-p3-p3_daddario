{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "from itertools import product\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading\n",
    "DATA_FOLDER = \"Data/\"\n",
    "\n",
    "epinions = pd.read_table(DATA_FOLDER + 'soc-sign-epinions.txt', \n",
    "                         names=['Source','Target','Weight'],comment='#',header=None).rename_axis('Epinions',axis=1)\n",
    "slashdot = pd.read_table(DATA_FOLDER + 'soc-sign-Slashdot090221.txt', \n",
    "                         names=['Source','Target','Weight'],comment='#',header=None).rename_axis('Slashdot',axis=1)\n",
    "wikielec = pd.read_csv(DATA_FOLDER + 'wikipedia.csv').rename_axis('Wikipedia',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Epinions</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>128552</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Epinions  Source  Target  Weight\n",
       "0              0       1      -1\n",
       "1              1  128552      -1\n",
       "2              2       3       1\n",
       "3              4       5      -1\n",
       "4              4     155      -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Slashdot</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Slashdot  Source  Target  Weight\n",
       "0              0       1       1\n",
       "1              0       2       1\n",
       "2              0       3       1\n",
       "3              0       4       1\n",
       "4              0       5       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Wikipedia</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Wikipedia  Source  Target  Weight\n",
       "0               3      30       1\n",
       "1              25      30      -1\n",
       "2               4      30       1\n",
       "3               5      30       1\n",
       "4               6      30       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display of the same structures datasets\n",
    "display(epinions.head())\n",
    "display(slashdot.head())\n",
    "display(wikielec.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First part - Weight average prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction method is used to predict edges' weight locally. That means that we do not look at the overall structure of the graph but only at a few nodes. The idea behind this technique is simple. To predict the weight of an edge, we only look at the two nodes forming this edge as well as their connected edges. First, we calculate the average of weights of the outgoing edges for the source node. Then, we also calculate the average of weights of the ingoing edges for the target node. Finally we compare those two means:\n",
    "\n",
    "- If both are positive, the predicted edge will be positive\n",
    "- If both are negative, the predicted edge will be negative\n",
    "- If the two means have different signs, the sign of the largest mean in absolute value will give the edge prediction\n",
    "\n",
    "For example, if the average of outgoing edges is -0.7 and the average of ingoing edges is 0.3, the predicted edge will then be -1.\n",
    "\n",
    "###### Why such an algorithm ?\n",
    "The idea behind this algorithm is that both people's personnality and performance affects the final link between two people. In this algorithm, performance would typically be the average of ingoing weights for the target node and personnality would be the outgoing weights average for the source node. Personnality is important because people do not always rate other people based on an impersonal choice. For example, wikipedia adminiship voters should theoritically vote based on the candidate capability to be administrator and not based on anything else. Performance is important because it reflects how the target appears to other people. For example, on `epinions` dataset, people might be more trustworthy than others and give a general better impression to people. So this algorithm tries to predict edges based on people's performance and personnality and not based on subgraph connections like balance and status theories do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation method\n",
    "Before jumping into the algorithms, we will explain the method used to evaluate our results. We are in the case of a binary classifier (+1 and -1) so we need to evaluate both class. We could use a f-score evaluation but the problem is that this method only evaluates the psotive class (precision and recall on positives). So what we will use is the Matthews correlation coefficient which is given by:\n",
    "\n",
    "$$ MCC=\\frac{TP*TN-FP*FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}} $$\n",
    "\n",
    "This coefficient gives a measure of the quality of a binary classification and will therefore be used to evaluate our predictions. We also give the precision, recall and f-score for each of the binary classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results Epinions Slashdot Wikipedia\n",
       "Class   Score                                 \n",
       "+1      Precision       NaN      NaN       NaN\n",
       "        Recall          NaN      NaN       NaN\n",
       "        F-score         NaN      NaN       NaN\n",
       "-1      Precision       NaN      NaN       NaN\n",
       "        Recall          NaN      NaN       NaN\n",
       "        F-score         NaN      NaN       NaN\n",
       "General Accuracy        NaN      NaN       NaN\n",
       "        MCC             NaN      NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = list(product(['+1', '-1'], ['Precision', 'Recall', 'F-score'])) + [(\"General\",\"Accuracy\"),(\"General\",\"MCC\")]\n",
    "\n",
    "evaluation_results = pd.DataFrame(columns=[\"Epinions\", \"Slashdot\", \"Wikipedia\"], \n",
    "                                  index=pd.MultiIndex.from_tuples(index, names=['Class', 'Score']))\\\n",
    "                                  .rename_axis('Evaluation results',axis=1)\n",
    "\n",
    "display(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_evaluation(G):\n",
    "    \n",
    "    TP = TN = FP = FN = 0\n",
    "    \n",
    "    for e in G.edges:\n",
    "        if G.edges[e]['Weight'] == G.edges[e]['Predict']:\n",
    "            if G.edges[e]['Weight'] > 0:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if G.edges[e]['Predict'] > 0:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    \n",
    "    precision_pos = TP/(TP+FP)\n",
    "    recall_pos    = TP/(TP+FN)\n",
    "    precision_neg = TN/(TN+FN)\n",
    "    recall_neg    = TN/(TN+FP)\n",
    "    F_score_pos = (2*precision_pos*recall_pos/(precision_pos + recall_pos)) if precision_pos + recall_pos != 0 else 0\n",
    "    F_score_neg = (2*precision_neg*recall_neg/(precision_neg + recall_neg)) if precision_neg + recall_neg != 0 else 0\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    \n",
    "    if TP*TN*FP*FN == 0:\n",
    "        MCC = 0\n",
    "    else:\n",
    "        MCC = (TP*TN - FP*FN)/np.sqrt(float((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "    \n",
    "    return (precision_pos, recall_pos, F_score_pos, \n",
    "            precision_neg, recall_neg, F_score_neg,\n",
    "            accuracy, MCC)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First algorithm\n",
    "The first algorithm `average_predict` is the one we have described above. It will first calculate the mean of outgoing weights and ingoing weights for every nodes and store them as attributes `Source score` and `Target score`. Then, for every edges, it will compare the source node score (average outgoing weights) and target node score (average ingoing weights) and predict the sign as explained above. Note that this is not a real case of prediction as we also count the weight of the edge that we want to predict in the averages. This first algorithm is implemented to get a first impression of the results that we could get. Furthermore, it is much faster than the next agorithms so we will use this speed to find some parameters in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_predict(dataframe):\n",
    "    # Dataframe to Graph\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "\n",
    "    # Set source and target nodes attribute (ingoing and outgoing averages)\n",
    "    for node in G.nodes:\n",
    "        out_edges_weight = [G.get_edge_data(*e)['Weight'] for e in G.out_edges(node)]\n",
    "        in_edges_weight  = [G.get_edge_data(*e)['Weight'] for e in G.in_edges(node)]\n",
    "        G.nodes[node][\"Source score\"] = np.mean(out_edges_weight) if len(out_edges_weight) > 0 else np.nan\n",
    "        G.nodes[node][\"Target score\"] = np.mean(in_edges_weight)  if len(in_edges_weight)  > 0 else np.nan\n",
    "\n",
    "    # Compare node attributes for each edges\n",
    "    for e in G.edges:\n",
    "        # Retrieve node attributes\n",
    "        s = G.nodes[e[0]]['Source score']\n",
    "        t = G.nodes[e[1]]['Target score']\n",
    "        if np.isnan(s) or np.isnan(t):\n",
    "            raise ValueError(\"nan sould not be there\")\n",
    "        \n",
    "        # Case where source and target weight averages have same signs\n",
    "        if s*t > 0:\n",
    "            # Both are positive\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            # Both are negative\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "        \n",
    "        # Case where source and target weight averages have opposite signs\n",
    "        elif s*t < 0:\n",
    "            if s > 0:\n",
    "                # Get the largest of the two averages (absolute value)\n",
    "                if s > abs(t):\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s < abs(t):\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                # Both are equal -> we guess\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "            else:\n",
    "                # Get the largest of the two averages (absolute value)\n",
    "                if abs(s) > t:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                elif abs(s) < t:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                # Both are equal -> we guess\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "                    \n",
    "        # Case where one of the two source and target weight averages is 0\n",
    "        else:\n",
    "            if s + t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s + t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "    \n",
    "    # Evaluation\n",
    "    return weighted_average_evaluation(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 158 ms, total: 13.7 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%time evaluation_results[\"Epinions\"] = average_predict(epinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.8 s, sys: 71.3 ms, total: 8.88 s\n",
      "Wall time: 8.88 s\n"
     ]
    }
   ],
   "source": [
    "%time evaluation_results[\"Slashdot\"] = average_predict(slashdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 7.7 ms, total: 1.45 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%time evaluation_results[\"Wikipedia\"] = average_predict(wikielec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                    \n",
       "+1      Precision      0.948     0.879      0.859\n",
       "        Recall         0.998     0.985      0.992\n",
       "        F-score        0.972     0.929      0.921\n",
       "-1      Precision      0.980     0.915      0.932\n",
       "        Recall         0.684     0.537      0.396\n",
       "        F-score        0.806     0.677      0.556\n",
       "General Accuracy       0.951     0.884      0.866\n",
       "        MCC            0.795     0.644      0.554"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(evaluation_results.round(decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "We can see that the accuracies of our predictions for all datasets are already surprisingly good. But. The problem with our datasets is that they contain a lot more positive edges than negative ones. So the average of weights will more often be positve because there are just more positive edges. If we exagerate the idea, it's just as if we put all weights to +1 so that, as the positive weights are dominant, the accuracy will be high. This is why we need a binary class evaluation method to also evaluate the negative weight predictions. This evaluation problem can easily be resolved if we look at the recall on negative evaluations and see that they are low compared to the other evaluations. Having a low recall on negative weights simply means that there are too much false positives which means that too many weights were predicted to be positive as they were in reality negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second algorithm\n",
    "To adress the problem of unbalanced classes, we added a new parameter to restore the balance. As we have seen before, the problem is that the negative weights are under-represented. So we added a parameter `alpha` to ponderate the classes and which quantifies the importance of the negative weights class. This parameter range is between 0 and 1. For example, `alpha=1` would mean that you give all importance to negative weights. This would results in predicting that all edges are equal to -1. The same reasoning applies when `alpha=0` which leads to predicting that all edges are equal to 1.\n",
    "\n",
    "So the following algorithm takes as parameter `alpha`. It is the exact same algorithm than the previous one except that it adds a new edge attribute `Modified Weight` which contains the ponderated weights. So, the modified weights are as follow:\n",
    "\n",
    "\\begin{alignat*}{2}\n",
    "+1 &\\rightarrow +1*(1-\\alpha) \\\\\n",
    "-1 &\\rightarrow -1*(\\alpha)\n",
    "\\end{alignat*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_predict(dataframe, alpha):\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "    \n",
    "    # Edge ponderation\n",
    "    for e in G.edges:\n",
    "        G.edges[e]['Modified Weight'] = (1-alpha) if G.edges[e]['Weight'] > 0 else -alpha\n",
    "    \n",
    "    # Average considering the modified weight\n",
    "    for node in G.nodes:\n",
    "        out_edges_weight = [G.get_edge_data(*e)['Modified Weight'] for e in G.out_edges(node)]\n",
    "        in_edges_weight  = [G.get_edge_data(*e)['Modified Weight'] for e in G.in_edges(node)]\n",
    "        G.nodes[node][\"Source score\"] = np.mean(out_edges_weight) if len(out_edges_weight) > 0 else np.nan\n",
    "        G.nodes[node][\"Target score\"] = np.mean(in_edges_weight)  if len(in_edges_weight)  > 0 else np.nan\n",
    "\n",
    "\n",
    "    for e in G.edges:\n",
    "        s = G.nodes[e[0]]['Source score']\n",
    "        t = G.nodes[e[1]]['Target score']\n",
    "        if np.isnan(s) or np.isnan(t):\n",
    "            raise ValueError(\"nan cannot exist here\")\n",
    "\n",
    "        if s*t > 0:\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "\n",
    "        elif s*t < 0:\n",
    "            if s > 0:\n",
    "                if s > abs(t):\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s < abs(t):\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "            else:\n",
    "                if abs(s) > t:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                elif abs(s) < t:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "        else:\n",
    "            if s + t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s + t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "    return weighted_average_evaluation(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look for a the right parameter `alpha`, we implemented the following gradient descent algorithm. The parameter to optimize is `alpha` and the loss function is based on Matthews correlation coefficient (MCC). We want to find the optimal parameter `alpha` such that the MCC is maximized. Unfortunately, it is very sensible to parameters such as the learning rate and the initial parameters so it is hardly generalizable to all datasets. Furthermore, it oftens fall into local minimums which, in the end, will not give the optimal `alpha`.\n",
    "\n",
    "Here is an example of some iterations from the algorithm where it converges to the optimal value. The initial parameters are 2 instances of `alpha`. We know that the ponderation has to be towards the negative weights so we can initialize the `alpha` instances to 0.5 and 0.55. The loss function is initialized to its optimal 1. Finally, the learning rate used here is 1 and the algorithm stops when the difference of two consecutives `alpha` is less than 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_new: 0.6016060508481715\n",
      "Delta: 0.05160605084817149 \n",
      "\n",
      "alpha_new: 0.6370826226850989\n",
      "Delta: 0.03547657183692732 \n",
      "\n",
      "alpha_new: 0.6538446743130801\n",
      "Delta: 0.016762051627981278 \n",
      "\n",
      "alpha_new: 0.6591776550509444\n",
      "Delta: 0.005332980737864257 \n",
      "\n",
      "alpha_new: 0.6599432943246093\n",
      "Delta: 0.0007656392736649087 \n",
      "\n",
      "alpha_new: 0.6604409554633216\n",
      "Delta: 0.000497661138712302 \n",
      "\n",
      "alpha_new: 0.6601242501609728\n",
      "Delta: 0.00031670530234884087 \n",
      "\n",
      "alpha_new: 0.6601916342643964\n",
      "Delta: 6.738410342366219e-05 \n",
      "\n",
      "alpha optimal: 0.6601916342643964\n",
      "MCC for the optimal alpha: 0.6644898458528367\n"
     ]
    }
   ],
   "source": [
    "delta = np.inf\n",
    "alpha_prec = 0.5\n",
    "alpha = 0.55\n",
    "gamma = 1\n",
    "f = 1\n",
    "while delta > 1e-4:\n",
    "    f_prec = weighted_average_predict(wikielec, alpha_prec)\n",
    "    f = weighted_average_predict(wikielec, alpha)\n",
    "    alpha_new = alpha + gamma*(f[-1]-f_prec[-1])\n",
    "    delta = abs(alpha_new - alpha)\n",
    "    alpha_prec = alpha\n",
    "    alpha = alpha_new\n",
    "    print(\"alpha_new:\",alpha_new)\n",
    "    print(\"Delta:\",delta,\"\\n\")\n",
    "print(\"alpha optimal:\", alpha_new)\n",
    "print(\"MCC for the optimal alpha:\", f[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we find that the optimal value for `alpha` is 0.664. We find the optimal `alpha` for other datasets by iterating by hand because, in the end, it takes more time to find the good parameters to get the optimal value than just iterating by ourselves.\n",
    "\n",
    "We can also plot the MCC coefficients for different `alpha` and different datasets to illustrate the behaviour of the parameter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABNE0lEQVR4nO3dd3yN1x/A8c/JlkmGERE7CGLF3lvNql3aorU3bWm1KO2vWmorjVXVKlXVqqJGqL0JYouRmIlIJJF9z++PJwiCIHcl5/165ZXce8+9zzeXPN/7nPE9QkqJoiiKknNZGDsARVEUxbhUIlAURcnhVCJQFEXJ4VQiUBRFyeFUIlAURcnhrIwdwMtyd3eXRYoUMXYYiqIoZuXw4cMRUkqPjB4zu0RQpEgRDh06ZOwwFEVRzIoQ4sqzHlNdQ4qiKDmcSgSKoig5nEoEiqIoOZzZjRFkJDk5mbCwMBISEowdSrZgZ2eHl5cX1tbWxg5FURQDyBaJICwsDCcnJ4oUKYIQwtjhmDUpJXfu3CEsLIyiRYsaOxxFUQwgW3QNJSQk4ObmppJAFhBC4Obmpq6uFCUHyRaJAFBJIAup91JRcpZs0TWkKMqrkVISk5hCeEziY1/R8clYWwqsLS2wsbJ4+N3midvWlgLbx24/amNjaYH1g++WQn3AMGEqEWQRS0tLypcv//B2165dGTNmzDPbz58/H3t7e959991ntjl06BA//fQTs2bNytJYlewvITmViNh0J/fYx0/06W8npuj0Ho+FgJJ5nahQyIUKhXJTsVBuSuVzwsoy23RKmDVhbhvT+Pv7yydXFp8+fZoyZcoYKSKNo6MjsbGxRo0hK5nCe6o8X6pOcuJaNDvPhXPudizhMQkPT+73ElIyfI6rgw0ejrZ4OKX7yuC2Sy5rUnSSpFQdySk6klN1JKZ91+6TJKWmkpTyeJukVB1JKbqH9yWl6khOlcQlpnD6xj2OhUZx934yAHbWFpTzfJQYKhbKjVeeXOrKQU+EEIellP4ZPaauCPSsSJEidOnShW3btgGwfPlySpQowYQJE3B0dOTDDz+kQYMGVK9enW3bthEVFcWiRYuoW7cu27dvZ+rUqaxbt47IyEh69+5NSEgI9vb2BAQE4Ofnx4QJE7h69SohISFcvXqV4cOHM3ToUOLi4ujcuTNhYWGkpqby+eef06VLFyO/G8rrun0vgR3nI/jvXDi7zoc/PKkWdrMnr5MtpfI7UaeE+xMndjs8nGxxc7TB+iU+gdtYCGysLMA26+KXUhIaGc+xsCiCQqM4FhrFz/uusGjXJUBLVBW8XKhYKI929eCVmzwONlkXgJKhbJcIvvg7mFPX72Xpa/p6OjO+TdnntomPj6dixYoPb3/yyScPT7zOzs4cOHCAn376ieHDh7Nu3bqnnp+SksKBAwdYv349X3zxBVu2bHns8fHjx1OpUiX+/PNPAgMDeffddzl27BgAZ86cYdu2bcTExFCqVCkGDBjAxo0b8fT05J9//gEgOjr6Nd4BxViSUnQcuhLJf+fC2XEugtM3tP/b7o62NCyVl/qlPKhTwh03xyw8W+uREAJvN3u83expW8ETgORUHWdvxnAsVEsOQWFRbD8XzoPOisJu9lQslJsKXrmpUCg3ZT2dsbO2NOJvkf3oNREIIVoAMwFLYKGUcvITj7sAPwPeabFMlVIu0WdM+pIrV66HJ+YndevW7eH3ESNGZNjmrbfeAqBKlSpcvnz5qcd37drF6tWrAWjUqBF37tx5eHJv1aoVtra22NrakjdvXm7dukX58uX58MMPGT16NK1bt6Zu3bqv+RsqhnLlTlzaiT+cPRfvcD8pFSsLgX+RPHzcohT1fTwok98ZC4vs0YVibWlBuYIulCvoQo8ahQGITUzheFgUQaHRBIVGsT8kkr+OXQfAykJQpoAzTX3z8V6tIrjkUgsfX5feEoEQwhKYCzQFwoCDQoi1UspT6ZoNAk5JKdsIITyAs0KIX6SUSa963Bd9cjeG9H2ez+r/tLXVPtFZWlqSkvJ0/25GYzkPXuvBc9M/38fHh8OHD7N+/Xo++eQTmjVrxrhx417r91D0Iy4xhb0X77DjfDj/nQvnyp37ABRyzcVblQtS3ycvNYu74Wib7S7gn8nR1opaxd2pVdz94X03oxMISutSOnTlLtM2n2PBjhB61S5C7zpFyW2vupBelT7/Z1UDLkgpQwCEECuAdkD6RCABJ6Gd0RyBSCDjUS4ztnLlSsaMGcPKlSupWbPmK71GvXr1+OWXX/j888/Zvn077u7uODs7P7P99evXcXV1pUePHjg6OvLjjz++YvRKVpNScvpGzMNP/YeuRJKcKsllbUnN4m70rl2Uej4eFHGzVwOn6eR3sSO/S36al80PwMlr0cwJvMCswAss2nWJ92oV4YO6xXBVYwovTZ+JoCAQmu52GFD9iTZzgLXAdcAJ6CKlfGoumxCiL9AXwNvbWy/Bvq4nxwhatGjB5MlaT1hiYiLVq1dHp9Px66+/vtLrT5gwgV69euHn54e9vT1Lly59bvsTJ07w0UcfYWFhgbW1NfPmzXul4ypZKyg0imErjnI57VN/6fxO9K5dlPo+HlQpkgdbK9X3nVnlCrow/50qnLl5jzmBF5j330V+3HOZd2oU5oO6xfBwMo9xE1Ogt+mjQohOQHMp5Qdpt98Bqkkph6Rr0xGoDYwEigObgQpSymeO9prq9NFnebCRjru7+4sbmxBTfk/NkZSSXw+EMmFtMB5OtgxrUpL6Ph7kc7YzdmjZxoXbMcwJvMDaoOvYWFnwdrXC9KtfTL3HaYw1fTQMKJTuthfaJ//0egGTpZaNLgghLgGlgQN6jEtRDCohOZXP/jzJ74fDqOfjwcwuFdWUSD0okdeJGV0rMbRxSeZuu8jSvZf5ef8VulUtRP8GxSngksvYIZosfSaCg0BJIURR4BrQFXj7iTZXgcbATiFEPqAUEKLHmAwuoxlASs5x9c59+v98mFM37jG0cUmGNS6JZTaZ7WOqink48l3nCgxrXJLvt1/gl/1X+fVAKJ38vRjQoDheeeyNHaLJ0VsikFKmCCEGA/+iTR9dLKUMFkL0T3t8PjAJ+FEIcQIQwGgpZYS+YlIUQwo8c4vhK44BsKRnVRqWzmvcgHIYbzd7JnfwY3CjEszbfpHfDoWy8mAoHSp7MbBhcQq7ORg7RJOhSkwoGVLv6atL1UlmbjnHrMAL+BZwZn6PKni7qU+hxnY9Kp4f/rvIrwdDSdVJ3qxYkEENi1PMw9HYoRmEKjGhKAZyNy6JoSuOsvN8BJ2qeDHpzXJqFayJ8Mydiy/alWNQwxL8sCOEX/ZfYc3RMNpW8GRwoxKUyOtk7BCNRiUCRckix8OiGPDzEcJjEvn6rfJ0rVpIrQMwQXmd7fi8tS/96xdn4c4Qlu27wl9B12nj58knLUvnyEFlVQM2C3311VeULVsWPz8/KlasyP79+2nQoAFPdmVlRs+ePfn999+zpN2MGTO4f//+S8egZI42NfQqHeftBeD3ATXpVs1bJQET5+Fkyycty7BrdCMG1C/Ov8E3afzdf8z/7yJJBijNbUpUIsgie/fuZd26dRw5coTjx4+zZcsWChUq9OInGoBKBPqTkJzKx78f55M/TlC9mCt/D6mDn1duY4elvARXBxs+blGaLSPrU7uEO5M3nOGNmTvYcyHnzFtRiSCL3LhxA3d394d1f9zd3fH09HyszYABA/D396ds2bKMHz/+4f1jxozB19cXPz8/Pvzww4f379ixg1q1alGsWLGHn/qllAwePBhfX19atWrF7du3H7bfunUrlSpVonz58vTu3ZvExERmzZrF9evXadiwIQ0bNtTnW5DjXL1znw7z9rDqcBhDG5fkx17VVHkDM1bI1Z4F7/qzuKc/yamStxfuZ8ivR7kZnf33785+YwQbxsDNE1n7mvnLwxuTn9ukWbNmTJw4ER8fH5o0aUKXLl2oX7/+Y22++uorXF1dSU1NpXHjxhw/fhwvLy/WrFnDmTNnEEIQFRX1sP2NGzfYtWsXZ86coW3btnTs2JE1a9Zw9uxZTpw4wa1bt/D19aV3794kJCTQs2dPtm7dio+PD++++y7z5s1j+PDhTJs2jW3btpnd6mZTpqaGZl+NSuejVnF35v93ke+3XyTw9C2GN/GhZ+0iL7WfgznJnr+VETg6OnL48GECAgLw8PCgS5cuTxV6++2336hcuTKVKlUiODiYU6dO4ezsjJ2dHR988AF//PEH9vaPphm++eabWFhY4Ovry61btwDtKqFbt25YWlri6elJo0aNADh79ixFixbFx8cHgPfee48dO3YY5pfPQVJ1kmmbztL7x0N45bFn3ZC6KglkQ3bWlgxv4sOWEfWpXsyNr9afptWsnewLuWPs0PQi+10RvOCTuz5ZWlrSoEEDGjRoQPny5R8rDHfp0iWmTp3KwYMHyZMnDz179iQhIQErKysOHDjA1q1bWbFiBXPmzCEwMBB4vLx0+vUeGQ1Cmtt6EHOkpobmPN5u9ix6z58tp28zYW0wXQP28WZFTz5tWYa82aiGkboiyCJnz57l/PnzD28fO3aMwoULP7x97949HBwccHFx4datW2zYsAGA2NhYoqOjadmyJTNmzHjm5jYP1KtXjxUrVpCamsqNGzceboFZunRpLl++zIULFwBYtmzZw64pJycnYmJisvLXzXGOh0XRevYu9odE8vVb5fm2o59KAjmEEIKmvvnYMrI+QxuVYP0JbXbR4l2XSEnNHrOLst8VgZHExsYyZMgQoqKisLKyokSJEgQEBNCxY0cAKlSoQKVKlShbtizFihWjdu3aAMTExNCuXTsSEhKQUjJ9+vTnHqd9+/YEBgZSvnx5fHx8Hp7s7ezsWLJkCZ06dSIlJYWqVavSv39/APr27csbb7xBgQIFHiYOJXOklKw4GMr4v7Sqob8PqKlmBeVQuWwsGdmsFO0rezF+bTAT153it0OhTHqzHFWLuBo7vNeiSkwoGVLvKUTHJ/P5nydZG3SduiXdmdm1kpoVpADaB4R/g28xad0prkXF81blgnzyRhmT3gNBlZhQlJd08HIkw1cc4+a9BEY19WFgwxKqaqjykBCCFuXyU8/HnbnbLhCwI4TNp27xYbNSdK/ujZWZzS4yr2gVRc+SU3V8t+ksXX7Yi5Wl4Pf+NRmiSkcrz2BvY8VHzUuzcXg9KnjlZvzaYNrO2c3hK5HGDu2lqESgKGmu3Imj0/y9zA68wFuVvfhnaF0qeecxdliKGSju4ciy96sx9+3KRMYl0WHeXj5aFUR0fLKxQ8sU1TWk5HhSSlYfucb4v05iaSGY83YlWvt5vviJipKOEIJWfgVoUMqDWYHnWbjzEvsvRfJ998qUK+hi7PCeSyUCJUeLvp/M2D9PsO74DaoVdWV6l4oUzJ3zqk8CkJIEYQfhYiDcPA6pySBTQadL+54CutRXuw8gX1koXAsK14FC1cDO2bi/r5442FrxyRtlaFomH4OXH+WteXsY38aXt024EKFKBEqOtT/kDiNWHuN2TCIfNS9F//rFc9ZYgJRw54J24r8YCJd3QVIsCEvI6wvWdmBhpd22tAYrO7Cw1G5bWIKw0B5/7D5LsLBI+57uMV0yXD8Ke2bDrunac/P7QZE6WnLwrgn25j0F80n+RVz5Z2gdRvwWxNg1Jzl4KZKv2pfHwdb0TrumF5GZGjFiBIULF2b48OEANG/enEKFCrFw4UIARo0ahYuLCzY2NowZM4aePXvSunXrh+sMHvjggw8YOXIkvr6+rx2To6MjsbGxXL9+naFDh2aqrHVOkJyqY8aWc3y//SKFXe1ZPaAWFQrlNnZYhnE/EkK2p538t8G9MO3+PEXBrwsUbwRF64KdnroykuK0q47Lu+HKHjiwAPbO0R7L6wuFa6ddNdQCp/z6icGA3Bxt+bFnVeZuu8D0Lec4ef0e87pXpmQ+09oERyWCLFKrVi1WrVrF8OHD0el0REREcO/evYeP79mzhxkzZlC9evXnvs6DxJGVPD09VRJIczkijmErjhIUFk1nfy/Gtylrkp/QskxKEoQdeHTiv34UkGDrAsXqQb1RUKwhuBY1TDw2DlCsgfYFkJII147AlV1aYji2HA4u0B5zLQ5Faj9KDrm9DRNjFrOwEAxpXJIqhfMwdMVR2s7Zzf/eKkf7Sl7GDu2hbPwXYFi1a9dmxIgRAAQHB1OuXDlu3LjB3bt3sbe35/Tp0wQFBbFs2TLmzJnz2HM///xzQkNDWbx4MY0aNWLq1Kn4+/vj6OhIv3792LZtG3ny5GHFihV4eHhw8eJFBg0aRHh4OPb29ixYsIDSpUtz6dIl3n77bVJSUmjRosXD1798+TKtW7fm5MmTXL58mXfeeYe4uDgA5syZQ61atQz3RhmJlJJVh8OYsDYYa0sLvu9emZblCxg7rKwnJUScf7y7JzlO657xqgoNPoHiDcGzMliawJ+/lS0Urql9AaSmwM2gR1cMp/6CIz9pj7kUSrtaSEsObsXBRPvcM1KrhDvrh9Zl8K9HGbEyiAOX7jK+ja9JlCoxgf8JWeubA99wJvJMlr5madfSjK42+rltPD09sbKy4urVq+zZs4eaNWty7do19u7di4uLC35+ftjYPL0q9eOPPyY6OpolS5Y8NZAUFxdH5cqV+e6775g4cSJffPEFc+bMoW/fvsyfP5+SJUuyf/9+Bg4cSGBgIMOGDWPAgAG8++67zJ07N8M48+bNy+bNm7Gzs+P8+fN069btlXZQMyfR95P5dM0J/jlxgxrFXJnWuSKe2WlAOCEaLmzRPvGn7+5xLQYVuuq/uycrWVpBwSraV+2h2mDz7VNwZbf2dTEQjq/U2haoAM2+hKL1jBvzS8jrbMfyD6ozbbPWNRkUGsX33StTxN3BqHFlu0RgTLVr12bPnj3s2bOHkSNHcu3aNfbs2YOLi0uGn7onTZpE9erVCQgIyPD1LCws6NKlCwA9evTgrbfeIjY2lj179tCpU6eH7RITEwHYvXs3q1evBuCdd95h9Oink1dycjKDBw/m2LFjWFpacu7cudf+vU3Z3ot3GPnbMcJjEhndojR96xXLPgPC0WGwbx4c/lEb5DVWd48+WVhA/nLaV/V+jwa4Q7bD7pmwtA34tICmE8GjlLGjzRQrSws+blEa/yJ5GLEyiDazd/FtRz/eMOIVarZLBC/65K5PtWrVYs+ePZw4cYJy5cpRqFAhvvvuO5ydnenduzd37jxey7xq1aocPnyYyMhIXF1fPGNCCIFOpyN37tzPrFL6oulp06dPJ1++fAQFBaHT6bCzyz6ldNNLStExfcs55v93kaJuDqwZWJvyXmbwiTgzbgXD7llw8nftxFiuA1R9Hwr6m0Z3jz4JAe4lta9KPWD/fNg5Db6vCZXfhYafgqN57A/RqHQ+/hlah0HLjzLglyP0rl2UMW+UxsbK8Ot81criLFS7dm3WrVuHq6srlpaWuLq6EhUVxd69e6lZs+ZT7Vu0aMGYMWNo1apVhmWidTrdw0He5cuXU6dOHZydnSlatCirVq0CtL7voKCgh8dfsWIFAL/88kuGMUZHR1OgQAEsLCxYtmwZqampWfK7m5KQ8Fg6zt/DvO0X6eJfiHVD65h/EpASLu2EnzvCvFpwei1U7QPDjkGHBeBdI/sngSdZ54I6I2DoMaj6ARxdBrMqwX/farOTzIBXHntW9atJz1pFWLz7El0C9nItKt7gcahEkIXKly9PREQENWrUeOw+FxeXZ24T2alTJ/r06UPbtm2Jj3/8P4CDgwPBwcFUqVKFwMBAxo0bB2gn+UWLFlGhQgXKli3LX3/9BcDMmTOZO3cuVatWJTo6OsPjDRw4kKVLl1KjRg3OnTuHg4Nx+yazkpSSXw9cpdWsXVyNvM/8HpWZ3MEPexszPkHqUiH4T1jQCJa21mb9NPwMRgRrmzCZ6UyaLOXgBi2/hUEHtIHwbV/B7Cpw9Gft/TNxNlYWTGhblu+7V+b8rVhazdrJtrO3X/zELKTKUJuwB+sAjMHc3tNb9xIYvfo428+GU6u4G9M6VyS/ixl3eyXHa1Mp98yGu5e0ef61hkDFt7VPwmZEJ3VcuXcFawtrctvmxsHaQb8rbK/ug3/HwrVDkLcsNJsEJRrr73hZ6FJEHAN/OcLpG/cY1LA4I5r4ZFklU1WGWsm2pJSsDbrOuL+CSUxJ5Yu2ZXmnRmEszHVA+H4kHFyk9X3fj9CmeTaZAGXaaKt0zYCUkqsxV9l/Yz/7buzj4M2DRCVGPXzcysIKFxsXctvmxsVW+57b7tHPz3rM2sI6cwF414APtsCpP2HzePj5LSjeWBtQzl9OL79zVinq7sCagbWYsDaYudsucvjKXWZ1raT3bTHVFYGSIXN4T+/EJvL5XydZf+Imlbxz812nChTzcDR2WK8m6irs/V6bM58cByWaQu1hWgkGM5grf/v+bfbf2K993dzPzbibAOSzz0f1AtXxz+ePEILoxGiiEqOISox6/OcE7eckXdIzj+Fg7fBYgqictzLdynTD2eY5NYtSEuHgQm3cICEaKnWHhmPB2fSLCq4+HMZnf57EwdaK2d0qUbO422u93vOuCLJNIihdurTJFnQyN1JKzpw5Y9KJYPOpW3zyx3Gi45MZ0dSHfvXMtE7QzRNpM4BWayf8ch21LiAT/+QanRjNoZuH2HdjH/tv7udS9CUAXGxdqJa/GtXzV6d6geoUdi6c6b9LKSXxKfHPThbpfr4Tf4fTkadxtHakW+luvOP7DnnsnlMyPP4u7JgKBwK0xXW1hmjrFGxNq9TDk87dimHAz4e5FBHHqGalGFC/+Ctf7Wb7RHDp0iWcnJxwc3NTyeA1SSm5c+cOMTExFC1qevPQ7yUkM/HvU/x+OIwyBZyZ1rkCZQqYWRVLKeHSDm0e/MWtYO0AVXpCjQGQu5Cxo8tQfEo8R28dZd/NfRy4cYDTkafRSR25rHJROV9lauSvQbUC1SjtWhoLYZg5KGcizxBwPIAtV7ZgZ2VHZ5/OvFf2PTzsPZ79pLuXYetELfE65NWmm1Z6x6RnXMUlpvDpmhP8dew6vWoXYXybsq/0Otk+ESQnJxMWFkZCQoKRospe7Ozs8PLywto6k32yBrL7QgQfrQri5r0EBjYowdDGJY0y5/q13D4Dawdrhdcc8mqLpKq+D7lMawOcZF0ywRHB2if+G/sJCg8iWZeMlbDCz8OP6gW0T/x+7n5YWxr3/8nFqIssPLGQ9ZfWYyWs6ODTgd7lepPf4TlF68IOw6bP4OoecC+lDSiXbGay3XDajLhQqhdzpfgrdn9m+0SgZG/3k1KYvOEMP+29QjEPB77rVMH8dg7T6bQB4C0TwNYRGn0GFd7WSj2bkOCIYFaeXcmmK5uIS9bm4pd2Lf2wq6dKvirYW9sbOcqMXb13lUUnF7H2wloQ0K54O94v9z6FnJ9xlSUlnPkHtozXVisXawBtZkKeIoYM22BUIlDM1uErkYz6LYjLd+7Tu3ZRPm5RyiSKdL2U6DD4c4DWHeTTAtrONqnVr/Ep8Wy8tJGVZ1cSfCeYXFa5aF6kOXUL1qVq/qrP73s3Qddjr7P45GLWnF9DqkylZdGWfFD+A4rlLpbxE1KT4dASrcsIqV0dVOllslcHr0olAsXsJKakMn3zeQJ2XKSASy6mdqrw2rMmDE5KOLEK/vlQ27WrxddaGQQTOcGERIew6uwq/rr4FzFJMRR3KU7nUp1pU7wNTjamPYiaGbfv32Zp8FJWnVtFQkoCTQs3pa9fX0q5PqMmUVSo1m0Xsl2r1dRuDriYTqno16USgWJWTl6LZtRvQZy9FUPXqoX4rLUvjua2Z8D9SPhnJASvgULVof18rRqokSXrkgm8GshvZ3/jwM0DWFlY0dS7KZ1LdaZKvirZcrJFZEIky04t49czvxKXHEeDQg3oW74v5T3KP91YSji0GDZ9rq3baPE1VOxuMsn7dahEoJiFlFQd87ZfZObW87g62PBNBz8aljadLpRMu7AF/hykLQhr+CnUHm70xWA3426y6twq/jj/BxHxEXg6eNKpVCfeLPEm7rkyLn+S3UQnRrP8zHJ+PvUz95LuUcuzFv38+lE5X+WnG0degr8Gaxvm+LSA1jPA2bz3r1CJQDF5F27HMuq3YwSFRdO2gicT25Ult/3T+zeYtKT7sHmctsOWR2lo/wN4VjRaODqpY8/1Paw8u5IdYTuQUlLXqy5dSnWhtmdtLM1kpXJWi0uOY8WZFfx06iciEyLxz+dPX7++1ChQ4/ErIp0ODvwAW77QNtBpOQXKdzLbqwOVCBSTpdNJFu++xJR/z2JvY8mXb5anlZ8ZfvK6dhj+6KvNPqkxEBqPM1pNoLsJd1lzYQ2rzq4iLDYMVztX3ir5Fh19OlLQsaBRYjJF8SnxrD63miUnl3A7/jaV81ZmUu1JeDs/Ucgv4oI22B92AEq31q4OHJ+zVsFEGS0RCCFaADMBS2ChlHJyBm0aADMAayBCSln/ea+pEkH2cSM6nhErj7EvJJImZfLyv7fKk9fJtKZTvlBqCuz8Dv77Rtts/c3vH+3Ha0BSSo6FH9Omfl7eRLIumSr5qtClVBeaeDcx+lx/U5aUmsSa82uYeXQmKboUxlQbQ/sS7Z+4OkiFvXMg8EttNXKraVD2TaPF/CqMkgiEEJbAOaApEAYcBLpJKU+la5Mb2AO0kFJeFULklVI+t/6qSgTZw7/BNxm9+jhJKTomtClLJ38v8xuojLgAa/pqVwPlO2tdB7lyGzQEKSXrQtaxJHgJ5++ex9HakTbF29DZpzMl8pQwaCzm7mbcTT7d9SkHbx6kiXcTxtccT2673I83un0G/uyvlQMv+xa0+g7sX7yplCkwViKoCUyQUjZPu/0JgJTy63RtBgKeUsrPMvu6KhGYt4TkVL765zTL9l2hXEFnZnerTFEj79f60qSEQ4vg38+0vuPW06HcWwYP49zdc3y17yuO3D5CqTyl6Fq6Ky2LtjTZBV/mQCd1LA1eyqyjs3C1dWVSnUnU8nxim9nUFNg1XbsKzJVHW4RWuqVxAn4Jz0sE+lyfXxAITXc7LO2+9HyAPEKI7UKIw0KId/UYj2Jk527F0G7Obpbtu0KfukX5Y0Bt80sCMTfhl47wzygoXBMG7jV4EohNiuXbg9/S+e/OhESHMLHWRH5r8xsdfTqqJPCaLIQFvcr1YnnL5TjaONJvcz++PfgtiamJjxpZWkH9j6DvNnDMByu6wZr+WmE7M6XPydkZXec/eflhBVQBGgO5gL1CiH1Sysd2VBdC9AX6Anh7qx2ZzI2Ukl/2X2XSulM42VmxtHc16vuY32AbwX/CuuGQnAAtp2rbIxqwO0tKycbLG5lycAoR8RF09OnI0EpDn+6+UF5bGbcyrGi9gmmHprHs1DL23djHN3W/oWSeko8a5S8PfQJhxxRtnChkO7SdAyWbGC3uV6XPK4IwIH2RDy/gegZtNkop46SUEcAOoMKTLySlDJBS+ksp/T08zPAEkoNF3U9iwM9H+OzPk1Qv5saGYfXMLwkkRMMf/WDVe9pOYf13QrU+Bk0CIdEh9Nnch493fIx7Lnd+afkL42qOU0lAj3JZ5WJsjbHMbTyXO/F36LquKz+f+hmd1D1qZGUDjcZqG+HYucAvHWDtEEi4Z7zAX4E+xwis0AaLGwPX0AaL35ZSBqdrUwaYAzQHbIADQFcp5clnva4aIzAf+0PuMHzlMSJiE/m4eWner1PU/HYOCz0Av/eGe9eh3kdQ70Mw4Ayc+8n3CTgewNJTS8lllYuhlYbSyadTjl0DYCx34u8wbs84doTtoLZnbSbVnvR0uevkBNj+NeyZBc4FtRIVRphB9izGnD7aEm1qqCWwWEr5lRCiP4CUcn5am4+AXoAObYrpjOe9pkoEpi8lVcfswAvMDjyPt6s9s7pVws8rt7HDejlSajtbbfxE282q42LwyvBvSE+HlwSGBvLNgW+4EXeDtsXbMrLKSNxymVm9pWxESslvZ39j6qGp2FnZMaHWBBp7Z7AXcugBbd3BnQvQ5AttpzkTmBGnFpQpBnMtKp7hK45y8PJd3qpckIntyplfnaDkeFg3AoJ+1WrUvxVg0P0CQu+F8vWBr9l5bScl85RkbPWxVMlXxWDHV54vJDqEMTvGcDryNB1KduDjqh8/PUifdB/+GqjVmqoxEJp9BRbG3TtDbV6vGMSGEzcYvfo4qTrJ9C4VaF/JDCs33r0MK3toW0jWHwP1RxvsDzgxNZHFJxaz8MRCrCys+Mj/I7qV6Zb5TdsVgyjmUoxfWv7CnGNzWHJyCYduHWJy3cmUc0+3vaiNPXRYrM0q2vc9xN6CN+dp041NkLoiUF5bfFIqk/45xfL9V6ng5cKsbpUo7GZm00JBKxb3+/uAhLcWgE9zgx16Z9hOvj7wNaExobQo0oIP/T8kn0M+gx1feTUHbx7k012fEnE/ggEVB/B+ufcfH7+REnbP0DYkKlofuvwMdsbZWlV1DSl6c/rGPYb+epTzt2PpV78Yo5qWMr/tI3U6bfrftq8gry90/dlgJaNvxN7gm4PfsPXqVoo4F2FsjbHUKFDDIMdWskZ0YjRf7fuKDZc3UDlvZf5X939P13Q6tlyrZprPF7qvBifDJ3mVCJQsJ6Vk2b4rfPnPaVxyWTOtcwXqljSzaaEA8VHaYqBzG7TKkm1mgo3+r2aSU5NZemopAccDkFLSr0I/3vN9T9UEMlMPSn18tf8rBIKxNcbSuljrxxud3wy/vQsOHvDOGnArbtAYVSJQstTduCQ++v04W07fokEpD6Z2qoC7o2n2fT7XrVOwsjtEXdUG86r3M8jsjgM3DvDl/i+5FH2JRoUaMbraaDwdPfV+XEX/wmLC+HTXpxy9fZQ3ir7BhJoTHh9IDjsMyztpP3dfBQUNNwlAJQIly+y9eIcRK49xJy6RMW+UoVetIua3NgDgxO/awh9bJ+i0VCsXoWdSSpadWsbUQ1Mp6FiQT6p/Qj2veno/rmJYKboUFp1YxPdB31OzQE1mN5r9+JVexAX4uT3ERUDnZQZbiWysWkNKNpKUouPbjWd4e+E+7G0sWTOwtnkuEEtNho2fwur3Ib8f9NthkCSQqkvl6wNfM+XQFJoUbsIf7f5QSSCbsrKwol+FfkyoOYHd13czeudoUnWpjxq4l4D3N2tdQ792gaAVxgs2jZo+qrzQxfBYhq84xolr0XTxL8S4Nr44mNvaAIDY27CqJ1zZDdX6at1BVvrfBe1+8n0+3vEx/4X9R8+yPRlRZQQWQn0Gy+7al2xPTFIMUw5N4Yu9X/BFrS8elVp3yg8912tdk2v6acUMjbjwzAz/mhVDkVKy4mAoE/8+ha21BfN7VKZFOTPcPQy01Z6/vasNDrcPgApdDHLY8PvhDNo6iLN3zzK2+li6lu5qkOMqpuHdsu8SkxzD/KD5ONo48pH/R4+SgZ0zdP9dm6ywZby21sBIC89UIlAyFBmXxOjVx9l86hZ1SrgztVMF8ruY2e5h8GjvgA1jwKUgfLBZqxppAOfvnmfQ1kFEJUYxu9Fs1RWUQw2sMJB7ifdYdmoZzjbO9K/Q/9GDVrbQYdGjhWcxN6H9fIMvPFOJQHnKjnPhjFoVRPT9ZD5rVYbetc1wLADSSkWMhKDlUKIpdFhgsFIRe6/vZeT2keSyysWPLX7E183XIMdVTI8QgtHVRhObHMvcY3NxsnGie5nujxpYWECLr7Xuoi3j4X4EdPnFoAvPVCJQHkpITuXbjWdZvPsSPvkcWdqrGr6exlkF+druXoaV78DN41qZiPpjDHbJveb8GibunUgRlyLMazKP/A75DXJcxXRZCAu+qPUFsUmxTD4wGUdrR9qVaPeogRBQZ7h2ZfDXIPixpUEXnqlEoABw5uY9hq84xpmbMfSsVYQxb5TGztpMSx0/KBUhJXRbCaVaGOSwUkrmHJtDwPEAahaoyXcNvsPJxskgx1ZMn5WFFVPqT2HQ1kGM2zMOB2sHmhR+YupoxW7g4K6NZy1qCj3+0GYZ6ZmaupDD6XSSxbsu0XbObiJik1jSqyoT2pY1zyQgJeyYCj931OrB991msCSQlJrEJ7s+IeB4AG+VfIu5TeaqJKA8xcbShpkNZ1LOvRwf7/iYPdf3PN2oZFN4bx0kxcLiZnDtsN7jUgvKcrDb9xIYtSqInecjaFImL5M7+JnnCmGAxFit7O+pv6BcB2g72yClIkCrNTNs2zAO3zrM0EpD+aD8B49mhihKBqITo+n1by/CYsIIaBpAxbwVn2505yIsaw9x4Vmy8EwtKFOesin4Js1n7ODg5Ui+fLMcC971N98kEHkJFjWD039D04naLAwDJYHQmFB6rO/B8fDjfFP3G/r49VFJQHkhF1sXApoG4JHLg4FbB3I28uzTjdyKP77w7NiveotHJYIc5n5SCp/8cYK+yw5TME8u1g2pS48ahc335HVxGyxoCPfCtNotBlyUExQeRI/1PbibeJcFzRbQslhLgxxXyR7cc7mzoNkC7K3s6bu5L1fuXXm6kVM+beFZ4VrwZ3/Y+71eYlGJIAc5HhZF61m7WHHwKv3rF+ePAbUpkdfR2GG9Gilh71z4+S1tpkWfbVDCMDVbADZf2cz7/76PvZU9y95YpnYQU16Jp6MnAc20CrR9NvXhZtzNpxs9WHjm1xU8SuklDjVGkAOk6iTz/7vI9M3n8HCyZVrnitQsbsZ73ybHw9/D4fgKKN1aW4Bja5iBWSklP536ie8OfUd5j/LMbjQbVztXgxxbyb5O3TnF+/++j3sud35s8aNe9qZWYwQ52LWoeLot2MeUf8/SvFx+Ng6rZ95JIPoaLHlDSwINPtEG0QyUBFJ0KXy1/yumHppKk8JNWNRskUoCSpbwdfNlTuM53Iy7Sf8t/bmXdM+gx1eJIBvbcOIGLWbsIPhaNN91qsCcbpVwsTfjjU+u7oOABhBxHrouhwaGWyR2P/k+w7YNY+XZlfQq24up9adiZ2WGJTcUk1UlXxWmN5zOhagLDN46mPiUeIMdWyWCbCgpRceEtcEM+OUIxT0c2TCsHh2qeJnvgDDAocXwY2uwdYQPtkLpVgY79O37t+m5sSe7ru3is+qfMdJ/pKoequhFnYJ1mFx3MkHhQYzYNoLk1GSDHFetLM5mwu7eZ9DyowSFRvF+naKMblHa/PYQTi8lCTZ8DIeXaIPBHRYarF4QQEh0CP029yM6MVoVjlMMonmR5sQmxTJh7wRG7xzNlHpTsLTQ7wJPlQiyka2nbzHytyB0Osn8HlVoUc7Ma9zE3taW2l/dC7WHQ+NxoOc/iPQuRl3k/X/fB2Bpi6WUcStjsGMrOVsHnw7EJscy9dDUp/cy0AOVCLKB5FQdUzed5Yf/Qijr6cz33StT2M0wC6r05toRWNEd4u9qC8TKdzTo4c/fPc8Hmz7AQliwqPkiirkUM+jxFeW9su9xL+keAccDnt7LIIupRGDmbkYnMOTXIxy8fJfu1b35vLWvedYJSi9oBawdCo554f1/oUAFgx7+3N1z9NnUB0thyaLmiyjqUtSgx1eUBwZXHExMUkzGexlkIZUIzNjO8+EMX3GM+ORUZnatSLuKBY0d0utJTYHN42DfXChSFzr9qFViNKCzkWfps6kP1hbWLGq+iCIuRQx6fEVJTwjBmGpjiE16xl4GWUQlAjOUqpPM2nqeWYHnKZnXke+7VzHfFcIP3I+E33tByHao1g+afwWWhp3qeibyDB9s+gA7SzsWN1+Mt7O3QY+vKBmxEBZMrD2RFJlCIadCejmGSgRmJjwmkeErj7L7wh06VPZi0ptlsbcx83/GW8HwazeIuQHt5kKlHgYP4dSdU/TZ1Ad7a3sWN1tMIWf9/MEpyquwsrDi23rf6u/19fbKSpbbH3KHIb8eJTo+mW87+NG5ajY4WZ36C9YM0FYH91wPhaoaPITgiGD6bO6Dk7UTi5ovwsvJy+AxKIoxqURgBnQ6yQ87Qpi66SzervYs7V2NMgXMdAvJB3SpEPgl7JoGXlW1UhHOBQwexonwE/Tb3A9nW2cWNV9EQUczH2dRlFfw3EQghBgJREspFz1x/xDAUko5Q4+xKcDduCRGrQoi8MxtWvkVYPJb5XGyM+MyEaCNB6z+AC5uhSo94Y1vwcrweyEcDz9Ov839cLF1YUnzJRRwNHwiUhRT8KIrgt5A5QzuDwAOAjOyOiDlkaNX7zJ4+VFuxyQwsV1Z3jHnfQMeuHkSVnbXise1ngH+vYwSxrHbx+i/pT+udq4sbr5YbTCv5GgvSgRSSpmUwZ2JwuzPSKZLSsmS3Zf5esNp8jnb8Xv/WlQolNvYYb2+k6vhr8Fg5wK91kOhakYJ4+jto/Tf3B8Pew8WNluokoCS471wjEAIkU9KeevJ+/QXUs52LyGZj1cdZ2PwTZqUycd3nSqYd8VQ0NYHbJ0Ae2ZDoRrQ+Sdt5yUjOHzrMAO2DCCffT4WNV9EXvu8RolDUUzJixLBFOAfIcQo4EjafVWAb4Gp+gwsJzp5LZpBy48QdjeesS3L8EHdoubfFZR+fUDVPtD8f2BlY5RQDt48yKCtg8jvkJ9FzRbhYe9hlDgUxdQ8NxFIKX8SQoQDE4FygASCgfFSyg0GiC9HeLCD2Iwt53BzsGVl3xr4F8kGG57cCIKVPSDmltHWBzxw4MYBBgcOxtPBk4XNF+Key7ArlhXFlL2wayjthK9O+npyOSKOUauCOHzlLi3L5+fLN8vj6mCcT8xZ6vhvsHYI2LtB7w1Q0Hh7+u67sY8hW4fg5eTFgmYLVBJQlCe8aProt0CIlHL+E/ePAPJLKUfrM7jsTErJ8gNX+eqf01haCGZ0qUi7ip7m3xWUmpxWL+h7KFxHqxfkaLwumD3X9zA0cCjezt4saLpAL3vBKoq5e9GOJa3Rpoo+aSbwwi2ihBAthBBnhRAXhBBjntOuqhAiVQhh2FrDRnL7XgK9fzzI2DUnqeSdm3+H1+PNSgXNPwnEhsOy9loSqD4A3v3TqElg97XdDNk6hMLOhVnUbJFKAoryDJmZPqrL4E7di6aPCiEsgblAUyAMOCiEWCulPJVBu2+Af18qcjO1/sQNxq45wf2kVMa38eW9mkWwsDDzBADa/gEr34H7EdA+ACp0MWo4O8N2MnzbcIrlLsaCpgvIbZfbqPEoiil7USK4L4QoKaU8n/5OIURJ4EU7K1cDLkgpQ9KeswJoB5x6ot0QYDVg+CIzBhQdn8yEtcGsOXqN8gVdmN6lovlXDH3g6C+wbgQ45oPe/4JnRaOG81/of4zYPoISuUuwoNkCXGxdjBqPopi6FyWCccAGIcSXwOG0+/yBT4DhL3huQSA03e0woHr6BkKIgkB7oBHPSQRCiL5AXwBvb/MrDbz7QgQfrgridkwiwxqXZHCjElhbmvE+wg+kJsO/n8KBAChaHzouAQfjdr8EXg1k1H+jKJWnFD80/UElAUXJhBdNH90ghHgT+Ajtkzto00c7SClPvOC1M+rvkE/cngGMllKmPq+nSUoZQNpYhb+//5OvYbISklP5ZuMZluy+TDF3B1YPqEXF7LBCGLQpoat6wtU9UGsINJ4AlsatYfhPyD+M3TUWXzdf5jedj7ONmRfmUxQDycz00ZPAe6/w2mFA+jrJXsD1J9r4AyvSkoA70FIIkSKl/PMVjmdSjodFMWLlMS6Gx/FezcKMeaMMuWzMfAvJB8IOaesD4qOMsp9wRladW8WkvZPwz+/P7EazcbA28z2bFcWAXjR9dO3zHpdStn3OwweBkkKIosA1oCvw9hPPf7gZrBDiR2CduSeBlFQdc7ddZHbgedwdbVn2fjXqlsxGK1iP/AT/jAKnAvDBZshf3tgR8ePJH/nu8HfULViXaQ2mYWdlZ+yQFMWsvOiKoCZaP/+vwH4y7u7JkJQyRQgxGG02kCWwWEoZLITon/b4/Oe+gBm6GB7LyN+CCAqNol1FTya2LWf+dYIeSLgH6z+E4yuheCPtSsDeuKufpZTMPTaXH47/QLPCzZhcdzLWBt7eUlGygxclgvxo0z+7oX2a/wf4VUoZnJkXl1KuB9Y/cV+GCUBK2TMzr2mKpJQs23eF/60/ja2VJXPerkRrP09jh5V1rh2G39+HqKvQcCzUHQUWxu3m0kkdUw5O4efTP9O+RHvG1xyPpZFjUhRz9aLB4lRgI7BRCGGLlhC2CyEmSilnGyJAU3czOoGPfg9i5/kI6vl4MKWjH/mcs0nXhE4He2ZqO4k5FdBKR3vXMHZUpOpS+WLvF6y5sIYeZXrwUdWPsBDZYBaWohhJZspQ26KtIu4GFAFmAX/oNyzzsDboOp+tOUFyqmTSm+XoUd3b/FcHPxBzE9b006qG+r4JbWZCrtxGDgqSU5MZs3MMm65son+F/gysMDD7vOeKYiQvGixeilZ1dAPwRdoMohwvITmV8X8Fs/JQKBUL5WZ6l4oUdc9Gs1TO/Qt/DoDkeGg7Gyq9AyZwsk1ISWDE9hHsuraLUVVG0bNcT2OHpCjZwouuCN4B4gAfYGi6T14CrfxEjpuoHRIey8BfjnDmZgwDGxRnZFMfrLLD4jCAlETYPB72z4N85aHjYvDwMXZUAMQmxTIkcAiHbx1mXM1xdPLpZOyQFCXbeNEYQTY5w2WNv4OuM2b1caytLFjSsyoNS2ej3a3Cz8HvveHWCa1gXJMJYG0aYx1RCVEM2DKA05GnmVx3Mi2LtTR2SIqSrRh3KaiZSEhO5ct/TvHzvqtU9s7NnLcr45k7l7HDyhpSwtFlsGE0WOeCt38Dn+bGjuqh8Pvh9N3cl6v3rjK9wXQaejc0dkiKku2oRPACV+7EMWj5EU5eu0efukX5uEXp7FEnCLSVwX8Pg1N/arWC3goAJ9PZyP167HX6bOpDeHw4c5vMpUYB489YUpTsSCWC59h48gYfrTqOELDgXX+a+hpnw3W9uLoPVveBmOtaN1CtYWBhOgnuUvQl+mzqw/2U+wQ0DaBi3orGDklRsi2VCDKQlKLj6w2nWbL7MhW8XJjzdmUKudobO6ysoUuFnd/B9q8htzf03gRexttGMiNnI8/Sd3NfABY3X0xp19JGjkhRsjeVCJ4Qdvc+g5YfJSg0ip61ivBpyzLYWJnOJ+XXEh0Gf/SFK7uhfGdo9R3YmdbEr2O3jzFw60DsrexZ0GwBRV2KvvhJiqK8FpUI0tly6hajVgWh00nmda/MG+ULGDukrHP6b/hrMOhSoP0PUKGrsSN6yr4b+xgaOBT3XO4sbLYQT8dsVKZDUUyYSgRAcqqOqf+e5YcdIZT1dOb77pUp7JZNFoglx2ubxxxaDJ6VtGJxbsWNHdVTtoduZ9T2UXg7exPQNAAP+2xUsVVRTFyOTwQ3ouMZvPwoh6/cpUcNbz5r5YuddTYpXnbzhDYgHH4aag+Dhp+BlY2xo3rK+pD1fLrrU8q4lmFek3lqf2FFMbAcnQi2n73NiJXHSErRMbNrRdpVLGjskLJGajLsmg7/fauViu7xB5RobOyoMvRgQ5nK+Sozp9EcHG2yyT7OimJGcmQiSEnVMWPLeeZsu0Dp/E7M7V6Z4h7Z5AR06xT82R9uBEH5TvDGt0bfNyAjOqlj9tHZLDyxkDoF6zCtwTRyWWWTRXqKYmZyXCK4fS+BIb8eZf+lSLr4F2JC27LZYwvJ1BStZPT2yWDrDJ2Xge/zNpAznoSUBMbuGsumK5vo6NORT6t/irWF2lBGUYwlRyWC3RciGLbiKHGJqXzXqQIdqngZO6SscfuMVi30+hEo2x5aTgUHd2NHlaE78XcYum0oJ8JPMKrKKN4r+54qI60oRpZjEsHaoOsMW3GU4h6O/NqnMiXzORk7pNenS4U9s2Hb/8DWETr9qCUCE3Ux6iKDtg7iTvwdpjWYRpPCTYwdkqIo5KBEUKeEO71qFeXD5j7Y22SDXzvivHYVEHYQyrSBVtPB0XSnXO69vpeR20dia2nLkhZLKOdeztghKYqSJhucETPH1cGGcW18jR3G69Olwr55EDhJqxbaYRGU62ASG8c8y+pzq/ly35cUcSnC3MZz1UIxRTExOSYRZAt3LsKfAyF0H5RqBa2ng5PpFsLTSR0zjsxgyckl1PaszZT6U3CyyQZdcoqSzahEYA50OjjwA2z5AqxsoX0A+HU26auA+JR4xu4ay+Yrm+ns05lPqn+ClYX676Yopkj9ZZq6yBCtRtCV3eDTAlrPAGfTroEUER/B0MChnIw4yYf+H/Ku77tqZpCimDCVCEyVTgeHFsHmcWBhDW/OgwrdTPoqAOD83fMM3jqYu4l3md5wOo29TXNFs6Ioj6hEYIruXtauAi7vhBJNoe0scDb9AdY91/Yw6r9R2FnZsaTFEsq6lTV2SIqiZIJKBKZESq1K6KbPwcIS2s6BSj1M/ioA4Lezv/G//f+jWO5izG00lwKOpt19pSjKIyoRmIrwc/DPSO0qoFhDaDsbchcydlQvpJM6ph2axtJTS6ldsDZT601VheMUxcyoRGBsSfdhxxRthbCNPbSZCZXfM4urgPiUeD7Z+Qlbr26lS6kujKk2Rs0MUhQzpP5qjenMetgwGqKvQsXu0OQLk14dnF74/XCGBA7h1J1TfFz1Y3qU6aFmBimKmVKJwBjuXtESwLkNkNcXem2AwrWMHVWmnbt7jkFbBxGdGM3MhjNp6N3Q2CEpivIaVCIwpJRErQtox1QQFtDsS6jeHyzNpwTzrmu7+PC/D3GwcuDHFj/i65YNynYoSg6nEoGhhGyHfz6EO+fBtx00/xpczGdHtBRdCgtOLGB+0HxK5i7JnMZzyO+Q39hhKYqSBVQi0LeYm/DvWDj5O+QpCt1XQ0nzKr98PfY6Y3aO4ejto7Qq1orPa3yOg7WDscNSFCWLqESgL6kpcHABBH4FqUnQ4BOoPRys7Ywd2UvZeGkjE/dORIeO/9X5H22KtzF2SIqiZDGVCPQh9ACsGwm3TkDxxtByCrgVN3ZULyUuOY6v93/NXxf/ws/dj8n1JlPIyfTXNSiK8vJUIshK9yNhy3g48hM4eULnn6BMW7NYE5DeyYiTjN4xmtCYUPr69aV/hf5qT2FFycZUIsgKOh0c+xk2j4eEaKg1BOqPBlvzqr2fqktlSfAS5h6di1suNxY3X4x/fn9jh6Uoip6pRPC6bp7QuoHCDoB3TWg1DfKZ35TKW3G3+HTXpxy4eYCmhZsyvuZ4XGxdjB2WoigGoBLBq0qM0TaN3z8fcrmaTZnojGy9spXxe8eTlJrExFoTebPEm2qVsKLkIHpNBEKIFsBMwBJYKKWc/MTj3YHRaTdjgQFSyiB9xpQlzm6Ef0bBvWtQpSc0Hgf2rsaO6qXFp8Qz5eAUVp1bha+bL9/U/YYiLkWMHZaiKAamt0QghLAE5gJNgTDgoBBirZTyVLpml4D6Usq7Qog3gACgur5iem0xt2DjaAheAx5loPe/4G264T7PmcgzfLzjYy5FX6JXuV4MqTgEazNa4awoStbR5xVBNeCClDIEQAixAmgHPEwEUso96drvA7z0GM+r0+ng6E/abmHJCdDoM6g1DKxsjB3ZS9NJHT+f+pkZR2aQ2zY3AU0DqOlZ09hhKYpiRPpMBAWB0HS3w3j+p/33gQ0ZPSCE6Av0BfD29s6q+DIn/BysG67tGVy4jlYm2r2EYWPIIhHxEXy26zN2X99Ng0INmFhrInns8hg7LEVRjEyfiSCj0UaZYUMhGqIlgjoZPS6lDEDrNsLf3z/D18hyKUmwe4a2V4C1vVntFpaRHWE7+Hz358Qlx/F5jc/p5NNJDQgrigLoNxGEAemXonoB159sJITwAxYCb0gp7+gxnsy7ug/+HgbhZ6BcB2gxGRzzGjuqV5KYmsi0Q9NYfmY5Pnl8WNx8McVzm9cqZ0VR9EufieAgUFIIURS4BnQF3k7fQAjhDfwBvCOlPKfHWDInIRq2TND2DXYpBG+vAp9mxo7qlZ2JPMOnuz7l/N3z9CjTg+FVhmNraWvssBRFMTF6SwRSyhQhxGDgX7Tpo4ullMFCiP5pj88HxgFuwPdp3RQpUkrjLGU9tRbWfwRxt6HGIGj4Kdia596795PvM/fYXH45/Qsuti7MbTyXel71jB2WoigmSkhpmC73rOLv7y8PHTqUdS8YfQ02fAxn1kH+8tBmFhSsnHWvb0BSSgJDA/l6/9fcun+LTj6dGFZ5mFohrCgKQojDz/qgnXNXFut0cGgRbPkCdCnQdCLUGGhWu4Wldz32Ol/v/5rtYdspmackU+tPpWLeisYOS1EUM5AzE8GtU9pgcNgBKNYQWk8D12LGjuqVJOuSWXZqGfOD5gMwqsoouvt2V9VCFUXJtJyVCJITtOmgu2eAnQu0DwC/zmY7JfTo7aNM3DuRC1EXaFCoAZ9W+5QCjgWMHZaiKGYm5ySC0IOwph9EXtSKwzX7ChzcjB3VK4lOjGb64emsPr+a/A75mdlwJo28Gxk7LEVRzFTOSQQWFtr3d/6E4g2NGsqrklLyd8jfTD04lXtJ9+hZticDKgzA3tre2KEpimLGck4iKFgFBh8EC0tjR/JKQqJD+HLflxy8eRA/Dz/G1RhHKddSxg5LUZRsIOckAjDLJJCQksCCEwtYfHIxuaxy8XmNz+no0xELYWHs0BRFySZyViIwM3uu7eHL/V8SGhNKq2Kt+ND/Q9xzuRs7LEVRshmVCExQ+P1wvj34LRsvb6Swc2EWNFtAjQI1jB2WoijZlEoEJiRVl8pv535j1pFZJKUmMbDiQHqX663qAymKolcqERiZlJIzkWfYfGUz/17+l6sxV6lRoAaf1fiMws6FjR2eoig5gEoERiClJPhOMJuubGLz5c2ExYZhKSypmr8qQyoPoXnh5mqvAEVRDEYlAgPRSR3Hw4+z+cpmNl/ZzI24G1gJK6p7VqePXx8aFmqodgtTFMUoVCLQo1RdKsfCjz08+d++fxtrC2tqedZiUMVBNCjUQFUGVRTF6FQiyGIpuhSO3DrCpiub2Hp1KxHxEdhY2FCnYB2aVmlKfa/6ONk4GTtMRVGUh1QiyALJumQO3jzI5iubCbwaSGRCJHaWdtT1qkuzws2o61UXB2sHY4epKIqSIZUIXsPBmwf5++LfBIYGEp0YTS6rXNT3qk/Twk2pU7COqgGkKIpZUIngFW2+spmR20fiYO1Ag0INaFq4KbU9a2NnZWfs0BRFUV6KSgSv4PSd04zdNRY/Dz8WNltILqtcxg5JURTllanKZS8pIj6CoduG4mLrwsyGM1USUBTF7KkrgpeQmJrIsG3DiE6MZmmLpaoAnKIo2YJKBJkkpeSLPV9wPPw40xpMo4xbGWOHpCiKkiVU11AmLQlewt8hfzOo4iCaFm5q7HAURVGyjEoEmbA9dDszDs+gRZEW9PPrZ+xwFEVRspRKBC9w7u45Ru8Yja+bL5NqT1LF4BRFyXZUIniOyIRIhgYOxcHagZkNZ6o1AoqiZEtqsPgZklOTGbFtBBHxESxpvoR8DvmMHZKiKIpeqESQASklX+7/kiO3j/BN3W8o71He2CEpiqLojeoaysAvp3/hj/N/0NevLy2LtTR2OIqiKHqlEsETdl3bxZRDU2js3ZhBFQcZOxxFURS9U4kgnZDoED767yNK5i7J/+r8Dwuh3h5FUbI/daZLE50YzZCtQ7CxtGF2o9mqhLSiKDmGGixG21hm1H+juBF3g8XNF1PAsYCxQ1IURTEYlQiAbw98y/4b+/my9pdUzFvR2OEoiqIYVI7vGlp5ZiUrzq6gV9letCvRztjhKIqiGFyOTgT7b+zn6wNfU9+rPsMqDzN2OIqiKEaRYxPB1XtXGbl9JEVdijK57mQsLSyNHZKiKIpR5MhEEJMUw+DAwVgIC2Y1moWjjaOxQ1IURTGaHDdYnKJL4aMdHxF6L5SAZgEUcipk7JAURVGMSq9XBEKIFkKIs0KIC0KIMRk8LoQQs9IePy6EqKzPeACmHZ7G7mu7GVtjLFXzV9X34RRFUUye3hKBEMISmAu8AfgC3YQQvk80ewMomfbVF5inr3gA/jj/B8tOLaNHmR509Omoz0MpiqKYDX1eEVQDLkgpQ6SUScAK4Mn5me2An6RmH5BbCKGX1VyHbx1m0r5J1PKsxSj/Ufo4hKIoilnSZyIoCISmux2Wdt/LtkEI0VcIcUgIcSg8PPyVgnG0dqRa/mpMqT8FK4scNzSiKIryTPpMBBnt6ShfoQ1SygAppb+U0t/Dw+OVginlWoofmv6As43zKz1fURQlu9JnIggD0k/J8QKuv0IbRVEURY/0mQgOAiWFEEWFEDZAV2DtE23WAu+mzR6qAURLKW/oMSZFURTlCXrrLJdSpgghBgP/ApbAYillsBCif9rj84H1QEvgAnAf6KWveBRFUZSM6XXUVEq5Hu1kn/6++el+loDaBkxRFMWIcmSJCUVRFOURlQgURVFyOJUIFEVRcjiVCBRFUXI4oY3Xmg8hRDhw5RWf7g5EZGE4+qBifH2mHh+YfoymHh+YfoymFl9hKWWGK3LNLhG8DiHEISmlv7HjeB4V4+sz9fjA9GM09fjA9GM09fjSU11DiqIoOZxKBIqiKDlcTksEAcYOIBNUjK/P1OMD04/R1OMD04/R1ON7KEeNESiKoihPy2lXBIqiKMoTVCJQFEXJ4bJlIhBCtBBCnBVCXBBCjMng8dJCiL1CiEQhxIcmGmN3IcTxtK89QogKJhZfu7TYjqXtHlfHkPFlJsZ07aoKIVKFEAbdqDoT72EDIUR02nt4TAgxzpDxZSbGdHEeE0IECyH+M7UYhRAfpXsPT6b9W7uaUHwuQoi/hRBBae+h6VVZllJmqy+0ktcXgWKADRAE+D7RJi9QFfgK+NBEY6wF5En7+Q1gv4nF58ijMSY/4IypvYfp2gWiVcHtaErxAQ2AdYb+//eSMeYGTgHeabfzmlqMT7RvAwSaUnzAp8A3aT97AJGAjbH+3TP6yo5XBNWAC1LKECllErACaJe+gZTytpTyIJBsjADJXIx7pJR3027uQ9u9zZTii5Vp/7MBBzLYYtTYMaYZAqwGbhsyODIfnzFlJsa3gT+klFdB+9sxwRjT6wb8apDINJmJTwJOQgiB9gEqEkgxYIwvlB0TQUEgNN3tsLT7TMnLxvg+sEGvET0uU/EJIdoLIc4A/wC9DRTbAy+MUQhREGgPzMfwMvtvXDOty2CDEKKsYUJ7KDMx+gB5hBDbhRCHhRDvGiw6Tab/VoQQ9kALtMRvKJmJbw5QBm0b3hPAMCmlzjDhZY5eN6YxEpHBfaY2RzbTMQohGqIlAkP2wWcqPinlGmCNEKIeMAloou/A0slMjDOA0VLKVO3DmEFlJr4jaPVfYoUQLYE/gZL6DiydzMRoBVQBGgO5gL1CiH1SynP6Di7Ny/w9twF2Sykj9RjPkzITX3PgGNAIKA5sFkLslFLe03NsmZYdrwjCgELpbnuhZWJTkqkYhRB+wEKgnZTyjoFig5d8D6WUO4DiQgh3fQeWTmZi9AdWCCEuAx2B74UQbxokukzEJ6W8J6WMTft5PWBtgu9hGLBRShknpYwAdgCGnLjwMv8Xu2LYbiHIXHy90LrXpJTyAnAJKG2g+DLH2IMUWf2F9gkmBCjKo8Gbss9oOwHjDBa/MEbAG20v51omGl8JHg0WVwauPbhtKjE+0f5HDDtYnJn3MH+697AacNXU3kO0Lo2taW3tgZNAOVOKMa2dC1rfu4OhYnuJ93AeMCHt53xpfyvuhozzRV/ZrmtISpkihBgM/Is2or9YShkshOif9vh8IUR+4BDgDOiEEMPRRvoNcqmWmRiBcYAb2qdYgBRpoEqGmYyvA/CuECIZiAe6yLT/6SYUo9FkMr6OwAAhRArae9jV1N5DKeVpIcRG4DigAxZKKU+aUoxpTdsDm6SUcYaK7SXimwT8KIQ4gdaVNFpqV1cmQ5WYUBRFyeGy4xiBoiiK8hJUIlAURcnhVCJQFEXJ4VQiUBRFyeFUIlAURcnhVCJQlJcghLj8okVfmWmjKKZEJQJFUZQcTiUCRXkGIcSfaYXWgoUQfZ94rIgQ4owQYmnavgy/pxU9e2CIEOKIEOKEEKJ02nOqpe0tcTTteymD/kKK8gwqESjKs/WWUlZBq1k0VAjh9sTjpYAAKaUfcA8YmO6xCCllZbTyAg82PzoD1JNSVkJbOf4/vUavKJmkEoGiPNtQIUQQ2n4QhXi6MmiolHJ32s8/83iF2D/Svh8GiqT97AKsEkKcBKYDhi47rSgZUolAUTIghGiAVla7ppSyAnAUsHui2ZP1WdLfTkz7nsqjcu+TgG1SynJoJZOffD1FMQqVCBQlYy7AXSnl/bQ+/hoZtPEWQtRM+7kbsCsTr3kt7eeeWRKlomQBlQgUJWMbASshxHG0T/L7MmhzGngvrY0r2njA83wLfC2E2I1WqVJRTIKqPqoor0AIUQRt4/lyxo5FUV6XuiJQFEXJ4dQVgaIoSg6nrggURVFyOJUIFEVRcjiVCBRFUXI4lQgURVFyOJUIFEVRcrj/A0+83PisRGAVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "alphas = np.arange(0.1,0.9,0.05)\n",
    "for df in [epinions, slashdot, wikielec]:\n",
    "    MCC = [0]*len(alphas)\n",
    "    for i,alpha in enumerate(alphas):\n",
    "        (_,_,_,_,_,_,_,MCC[i]) = weighted_average_predict(df, alpha)\n",
    "    plt.plot(alphas,MCC)\n",
    "    \n",
    "plt.legend((\"Epinions\", \"Slashdot\", \"Wikipedia\"))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MCC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results2 = evaluation_results.copy()\n",
    "evaluation_results2 = evaluation_results2.rename_axis(\"Evaluation results 2.0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 118 ms, total: 15.3 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "# Optimal alpha found by hand: 0.63\n",
    "%time evaluation_results2[\"Epinions\"] = weighted_average_predict(epinions, 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.99 s, sys: 73.4 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "# Optimal alpha found by hand: 0.63\n",
    "%time evaluation_results2[\"Slashdot\"] = weighted_average_predict(slashdot, 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 8.87 ms, total: 1.72 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "# Optimal alpha found by gradient descent: 0.66\n",
    "%time evaluation_results2[\"Wikipedia\"] = weighted_average_predict(wikielec, 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                    \n",
       "+1      Precision      0.948     0.879      0.859\n",
       "        Recall         0.998     0.985      0.992\n",
       "        F-score        0.972     0.929      0.921\n",
       "-1      Precision      0.980     0.915      0.932\n",
       "        Recall         0.684     0.537      0.396\n",
       "        F-score        0.806     0.677      0.556\n",
       "General Accuracy       0.951     0.884      0.866\n",
       "        MCC            0.795     0.644      0.554"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results 2.0</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.958</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results 2.0  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                        \n",
       "+1      Precision          0.970     0.934      0.924\n",
       "        Recall             0.981     0.935      0.938\n",
       "        F-score            0.975     0.934      0.931\n",
       "-1      Precision          0.883     0.777      0.755\n",
       "        Recall             0.821     0.773      0.712\n",
       "        F-score            0.851     0.775      0.733\n",
       "General Accuracy           0.958     0.898      0.890\n",
       "        MCC                0.827     0.709      0.664"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(evaluation_results.round(decimals=3))\n",
    "display(evaluation_results2.round(decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check\n",
    "Just to verifiy that our algorithm gives plausible results, we can see that when we use an `alpha` parameter of 0 or 1, the accuracy becomes equal to the percentage of positive (`alpha=0`) and negative (`alpha=1`) edges in the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.1f%%\"% (weighted_average_predict(epinions, 0)[-2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, what we just did is to predict that all edges are positive. Because there are 85.4% of positive edges in `epinions`, the accuracy becomes 85.4% as well. Note that in our last algorithm, the accuracy increased more than 10% with respect to the percentage of positive edges through all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "###### Score improvements\n",
    "The second table shows our new results compared to the older ones (first table). Now that the classes are balanced, the results are much better. We can see that all f-score increased when using a weight ponderation, especially the f-scores for the negative class. This is due to the fact that the recall for negative class has significantly increased. The cost of this is that the precision for negative class decreased but this decrease is lower than the recall inccrease making the overall statistics better. The higher recall for negative class also induced a balancing of precision and recall for the positive class which are now very close. The accuracy didn't increase much which is normal because we tried to balance the predictions rather than improve the number of correct predictions. \n",
    "\n",
    "###### Mystery coefficient\n",
    "Surprisingly, we can see that the optimal `alpha` parameter is pretty constant through the datasets (around 0.65). But what does this coefficient represent concretely ? At first, we chose this coefficient to balance the positive and negative classes. But intuitively, the optimal coefficient would be based on the ratio of positive and negative edges. For example, if there are 85% of positive edges like in `epinions`, the intuition would be to give a weight of 0.85 to the negative weights (`alpha=0.85`) and 0.15 to the positive ones. But this is not the case here. All `alpha` from the different datasets are underestimated with respect to this intuition. Indeed, the percentage of positive edges for `epinions`, `slashdot` and `wikielec` are respectively 85.0%,\t77.4% and 78.7% which are all way above our optimal parameter found of 0.65. What is even more surprising is how this optimal `alpha` keeps constant with different datasets and different ratios of positive/negative edges. This consistency goes toward the idea that this coefficient could have a broader signification. The first concrete hypothesis on the meaning of this coefficient would be that  **negative votes/ratings have more ease to tilt the scales than positive ones**. In other words, it confirms the fact that graphs often contain communities of condensed positives links where those communities are seperated by negative links. Indeed, it means that positive links are usually very condensed around nodes and that the average of outgoing/ingoing edges will definitely be positive (close to 1). On the other hand, negative links are often alone or close to a few postive links which make them a hard opponent against the positive links. So, as positive links are more condensed than negative ones, only a low `alpha` coefficient is required to make the negative links confrontable with positive links.\n",
    "\n",
    "###### Winner Dataset\n",
    "Even if `Wikipedia` has the lowest prediction scores in general, it is the dataset where the weight ponderation worked the best. This is very interesting as Wikipedia is indeed different from the other datasets. Its links are votes for adminship whereas the other datasets' links are more similar to \"user ratings\". If we consider the hypothesis stated above, that means that `Wikipedia` is the dataset which forms the most communities of positive votes. In other words, that means that votes are mostly oriented towards the same candidates and all other candidates only have a small impact on electors.\n",
    "###### Further research\n",
    "Some further research could be made based on the same idea of algorithm.\n",
    "- A first idea could be to also ponderate source and target nodes. For example, when comparing the avergage of outgoing edges from source and ingoing edges to target, we could give a higher importance to the target ingoing edges. We tried to implement this additional parameter but we only found optimals of 0.5 (equal importance), but maybe it couuld be an important factor on other datasets.   \n",
    "- A second idea was to use the time at which the edges were formed a give a decreasing exponential weight to links formed further away in time. In could be interesting to test this idead on several temporal signed networks and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Part - Real predicitons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last prediction algorithm that we have seen is not a real prediction algorithm as it also used the edge to predict in the averages. But the purpose of the previous part was mostly to understand the parameters and how to use them. Now, we will implement a real \"Leave One Out\" algorithm where we do not consider the weight of the edge that we want to predict and where we predict one edge at a time, knowing all the reamining graph. We then iterate through all edges and predict their weights. This algorithm complexity is higher than the previous one and this is why the parameters search was mostly done with the previous algorithm. Fortunately, the assumptions made previously still hold with this algorithm. What changed here is that we cannot compute the source and target score attributes as we did before so we need to calculate the averages on each edge, which is why it takes more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvo_weighted_average_predict(dataframe, alpha):\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "    \n",
    "    for e in G.edges:\n",
    "        G.edges[e]['Modified Weight'] = (1-alpha) if G.edges[e]['Weight'] > 0 else -alpha\n",
    "    \n",
    "    for e in G.edges:\n",
    "        # Calculate outgoing and ingoing weight averages for each edge without taking into account the edge to predict\n",
    "        out_edges_weight = [G.get_edge_data(*edge)['Modified Weight'] for edge in G.out_edges(e[0]) if edge != e]\n",
    "        in_edges_weight  = [G.get_edge_data(*edge)['Modified Weight'] for edge in G.in_edges(e[1])  if edge != e]\n",
    "        \n",
    "        # Lengths of source outgoing and target ingoing edge lists\n",
    "        len_out = len(out_edges_weight)\n",
    "        len_in  = len(in_edges_weight)\n",
    "        \n",
    "        # If both list lengths are 0 -> guess\n",
    "        if 0 == len_out == len_in:\n",
    "            G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        # If one of the two list lengths is 0 -> only consider one\n",
    "        elif len_out == 0:\n",
    "            t = np.mean(in_edges_weight)\n",
    "            if t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            # Case where t=0 -> guess\n",
    "            else:\n",
    "                 G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif len_in == 0:\n",
    "            s = np.mean(out_edges_weight)\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            # Case where s=0 -> guess\n",
    "            else:\n",
    "                 G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        # Case where both list lenghts are above 0 -> same as previous algo\n",
    "        else:\n",
    "            s = np.mean(out_edges_weight)\n",
    "            t = np.mean(in_edges_weight)\n",
    "            if s*t > 0:\n",
    "                if s > 0:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "\n",
    "            elif s*t < 0:\n",
    "                if s > 0:\n",
    "                    if s > abs(t):\n",
    "                        G.edges[e][\"Predict\"] = 1\n",
    "                    elif s < abs(t):\n",
    "                        G.edges[e][\"Predict\"] = -1\n",
    "                    else:\n",
    "                        G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "                else:\n",
    "                    if abs(s) > t:\n",
    "                        G.edges[e][\"Predict\"] = -1\n",
    "                    elif abs(s) < t:\n",
    "                        G.edges[e][\"Predict\"] = 1\n",
    "                    else:\n",
    "                        G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "            else:\n",
    "                if s + t > 0:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s + t < 0:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "    return weighted_average_evaluation(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results3 = evaluation_results.copy()\n",
    "evaluation_results3 = evaluation_results3.rename_axis(\"Evaluation results 3.0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 28s, sys: 791 ms, total: 4min 29s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "# Optimal alpha found by hand: 0.64\n",
    "%time evaluation_results3[\"Epinions\"] = lvo_weighted_average_predict(epinions, 0.64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 340 ms, total: 2min 5s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "# Optimal alpha found by hand: 0.64\n",
    "%time evaluation_results3[\"Slashdot\"] = lvo_weighted_average_predict(slashdot, 0.64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 39.2 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "# Optimal alpha found by hand: 0.67\n",
    "%time evaluation_results3[\"Wikipedia\"] = lvo_weighted_average_predict(wikielec, 0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results 2.0</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.958</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results 2.0  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                        \n",
       "+1      Precision          0.970     0.934      0.924\n",
       "        Recall             0.981     0.935      0.938\n",
       "        F-score            0.975     0.934      0.931\n",
       "-1      Precision          0.883     0.777      0.755\n",
       "        Recall             0.821     0.773      0.712\n",
       "        F-score            0.851     0.775      0.733\n",
       "General Accuracy           0.958     0.898      0.890\n",
       "        MCC                0.827     0.709      0.664"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results 3.0</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.769</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results 3.0  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                        \n",
       "+1      Precision          0.955     0.913      0.915\n",
       "        Recall             0.962     0.899      0.917\n",
       "        F-score            0.959     0.906      0.916\n",
       "-1      Precision          0.769     0.672      0.690\n",
       "        Recall             0.740     0.707      0.684\n",
       "        F-score            0.754     0.689      0.687\n",
       "General Accuracy           0.929     0.856      0.868\n",
       "        MCC                0.713     0.596      0.603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(evaluation_results2.round(decimals=3))\n",
    "display(evaluation_results3.round(decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we can see that even though we tried to find the best parameters by hand, they stay very close to the ones we found before which confirms our hypothesis that this coefficient might be generalizable.\n",
    "\n",
    "Second of all, we can see that the prediction performs less well than before mostly because this time, we didn't take into account the edge that we want to predict. The most affected score is the recall for the negative class just as before. Based on the MCC coefficient, we also see that the less affected dataset is `Wikipedia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpo_weighted_average_predict(dataframe, alpha, test_percent):\n",
    "    \n",
    "    df = dataframe.sample(round(test_percent*dataframe.shape[0])) \n",
    "\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "    \n",
    "    G_unknown = nx.from_pandas_edgelist(df, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "\n",
    "    for e in G.edges:\n",
    "        if e in G_unknown.edges:\n",
    "            G.edges[e]['Modified Weight'] = np.nan\n",
    "        else:\n",
    "            G.edges[e]['Modified Weight'] = (1-alpha) if G.edges[e]['Weight'] > 0 else -alpha\n",
    "        \n",
    "    for node in G_unknown.nodes:\n",
    "        out_edges_weight = [G.get_edge_data(*e)['Modified Weight'] for e in G.out_edges(node)]\n",
    "        in_edges_weight  = [G.get_edge_data(*e)['Modified Weight'] for e in G.in_edges(node)]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            G_unknown.nodes[node][\"Source score\"] = np.nanmean(out_edges_weight)\n",
    "            G_unknown.nodes[node][\"Target score\"] = np.nanmean(in_edges_weight)\n",
    "            \n",
    "    for e in G_unknown.edges:\n",
    "        s = G_unknown.nodes[e[0]]['Source score']\n",
    "        t = G_unknown.nodes[e[1]]['Target score']\n",
    "        if np.nan == s == t:\n",
    "            G_unknown.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif s == np.nan:\n",
    "            if t > 0:\n",
    "                G_unknown.edges[e][\"Predict\"] = 1\n",
    "            elif t < 0:\n",
    "                G_unknown.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G_unknown.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif t == np.nan:\n",
    "            if s > 0:\n",
    "                G_unknown.edges[e][\"Predict\"] = 1\n",
    "            elif s < 0:\n",
    "                G_unknown.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G_unknown.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        else:\n",
    "            if s*t > 0:\n",
    "                if s > 0:\n",
    "                    G_unknown.edges[e][\"Predict\"] = 1\n",
    "                else:\n",
    "                    G_unknown.edges[e][\"Predict\"] = -1\n",
    "\n",
    "            elif s*t < 0:\n",
    "                if s > 0:\n",
    "                    if s > abs(t):\n",
    "                        G_unknown.edges[e][\"Predict\"] = 1\n",
    "                    elif s < abs(t):\n",
    "                        G_unknown.edges[e][\"Predict\"] = -1\n",
    "                    else:\n",
    "                        G_unknown.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "                else:\n",
    "                    if abs(s) > t:\n",
    "                        G_unknown.edges[e][\"Predict\"] = -1\n",
    "                    elif abs(s) < t:\n",
    "                        G_unknown.edges[e][\"Predict\"] = 1\n",
    "                    else:\n",
    "                        G_unknown.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "            else:\n",
    "                if s + t > 0:\n",
    "                    G_unknown.edges[e][\"Predict\"] = 1\n",
    "                elif s + t < 0:\n",
    "                    G_unknown.edges[e][\"Predict\"] = -1\n",
    "                else:\n",
    "                    G_unknown.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "#\n",
    "    #TP = TN = FP = FN = 0\n",
    "    #\n",
    "    #for e in G_unknown.edges:\n",
    "    #    if G_unknown.edges[e]['Weight'] == G_unknown.edges[e]['Predict']:\n",
    "    #        if G_unknown.edges[e]['Weight'] > 0:\n",
    "    #            TP += 1\n",
    "    #        else:\n",
    "    #            TN += 1\n",
    "    #    else:\n",
    "    #        if G_unknown.edges[e]['Predict'] > 0:\n",
    "    #            FP += 1\n",
    "    #        else:\n",
    "    #            FN += 1\n",
    "    #\n",
    "    #precision_pos = TP/(TP+FP)\n",
    "    #recall_pos    = TP/(TP+FN)\n",
    "    #precision_neg = TN/(TN+FN)\n",
    "    #recall_neg    = TN/(TN+FP)\n",
    "    #F_score_pos = (2*precision_pos*recall_pos/(precision_pos + recall_pos)) if precision_pos + recall_pos != 0 else 0\n",
    "    #F_score_neg = (2*precision_neg*recall_neg/(precision_neg + recall_neg)) if precision_neg + recall_neg != 0 else 0\n",
    "    #accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    #\n",
    "    #if TP*TN*FP*FN == 0:\n",
    "    #    MCC = 0\n",
    "    #else:\n",
    "    #    MCC = (TP*TN - FP*FN)/np.sqrt(float((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "    #\n",
    "    #return (precision_pos, recall_pos, F_score_pos, \n",
    "    #        precision_neg, recall_neg, F_score_neg,\n",
    "    #        accuracy, MCC)\n",
    "    return weighted_average_evaluation(G_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results4 = evaluation_results.copy()\n",
    "evaluation_results4 = evaluation_results4.rename_axis(\"Evaluation results 4.0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 127 ms, total: 13.2 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%time evaluation_results4[\"Epinions\"] = wpo_weighted_average_predict(epinions, 0.64, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.63 s, sys: 90.4 ms, total: 8.72 s\n",
      "Wall time: 8.68 s\n"
     ]
    }
   ],
   "source": [
    "%time evaluation_results4[\"Slashdot\"] = wpo_weighted_average_predict(slashdot, 0.64, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 3.08 ms, total: 1.21 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%time evaluation_results4[\"Wikipedia\"] = wpo_weighted_average_predict(wikielec, 0.67, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results 3.0</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.769</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results 3.0  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                        \n",
       "+1      Precision          0.955     0.913      0.915\n",
       "        Recall             0.962     0.899      0.917\n",
       "        F-score            0.959     0.906      0.916\n",
       "-1      Precision          0.769     0.672      0.690\n",
       "        Recall             0.740     0.707      0.684\n",
       "        F-score            0.754     0.689      0.687\n",
       "General Accuracy           0.929     0.856      0.868\n",
       "        MCC                0.713     0.596      0.603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation results 4.0</th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">+1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.607</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-score</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">General</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluation results 4.0  Epinions  Slashdot  Wikipedia\n",
       "Class   Score                                        \n",
       "+1      Precision          0.952     0.904      0.915\n",
       "        Recall             0.918     0.860      0.908\n",
       "        F-score            0.935     0.882      0.911\n",
       "-1      Precision          0.607     0.587      0.665\n",
       "        Recall             0.735     0.684      0.686\n",
       "        F-score            0.665     0.632      0.675\n",
       "General Accuracy           0.891     0.821      0.861\n",
       "        MCC                0.604     0.517      0.587"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(evaluation_results3.round(decimals=3))\n",
    "display(evaluation_results4.round(decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
