{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading\n",
    "DATA_FOLDER = \"Data/\"\n",
    "\n",
    "epinions = pd.read_table(DATA_FOLDER + 'soc-sign-epinions.txt', \n",
    "                         names=['Source','Target','Weight'],comment='#',header=None).rename_axis('Epinions',axis=1)\n",
    "slashdot = pd.read_table(DATA_FOLDER + 'soc-sign-Slashdot090221.txt', \n",
    "                         names=['Source','Target','Weight'],comment='#',header=None).rename_axis('Slashdot',axis=1)\n",
    "wikielec = pd.read_csv(DATA_FOLDER + 'wikipedia.csv').rename_axis('Wikipedia',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Epinions</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>128552</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Epinions  Source  Target  Weight\n",
       "0              0       1      -1\n",
       "1              1  128552      -1\n",
       "2              2       3       1\n",
       "3              4       5      -1\n",
       "4              4     155      -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Slashdot</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Slashdot  Source  Target  Weight\n",
       "0              0       1       1\n",
       "1              0       2       1\n",
       "2              0       3       1\n",
       "3              0       4       1\n",
       "4              0       5       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Wikipedia</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Wikipedia  Source  Target  Weight\n",
       "0               3      30       1\n",
       "1              25      30      -1\n",
       "2               4      30       1\n",
       "3               5      30       1\n",
       "4               6      30       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display of the same structures datasets\n",
    "display(epinions.head())\n",
    "display(slashdot.head())\n",
    "display(wikielec.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAUL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight average prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction method is used to predict edges' weight locally. That means that we do not look at the overall structure of the graph but only at a few nodes. The idea behind this technique is simple. To predict the weight of an edge, we only look at the two nodes forming this edge as well as their connected edges. First, we calculate the average of weights of the outgoing edges for the source node. Then, we also calculate the average of weights of the ingoing edges for the target node. Finally we compare those two means:\n",
    "\n",
    "- If both are positive, the predicted edge will be positive\n",
    "- If both are negative, the predicted edge will be negative\n",
    "- If the two means have different signs, the sign of the largest mean in absolute value will give the edge prediction\n",
    "\n",
    "For example, if the average of outgoing edges is -0.7 and the average of ingoing edges is 0.3, the predicted edge will then be -1.\n",
    "\n",
    "###### Why such an algorithm ?\n",
    "The idea behind this algorithm is that both people's personnality and performance affects the final link between two people. In this algorithm, performance would typically be the average of ingoing weights for the target node and personnality would be the outgoing weights average for the source node. Personnality is important because people do not always rate other people based on an impersonal choice. For example, wikipedia adminiship voters should theoritically vote based on the candidate capability to be administrator and not based on anything else. Performance is important because it reflects how the target appears to other people. For example, on `epinions` dataset, people might be more trustworthy than others and give a general better impression to people. So this algorithm tries to predict edges based on people's performance and personnality and not based on subgraph connections like balance and status theories do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation method\n",
    "Before jumping into the algorithms, we will explain the method used to evaluate our results. We are in the case of a binary classifier (+1 and -1) so we need to evaluate both class. We could use a f-score evaluation but the problem is that this method only evaluates the psotive class (precision and recall on positives). So what we will use is the Matthews correlation coefficient which is given by:\n",
    "\n",
    "$$ MCC=\\frac{TP*TN-FP*FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}} $$\n",
    "\n",
    "This coefficient gives a measure of the quality of a binary classification and will therefore be used to evaluate our predictions. We also give the precision, recall and f-score for each of the binary classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_evaluation(G):\n",
    "    TP = TN = FP = FN = 0\n",
    "    for e in G.edges:\n",
    "        if G.edges[e]['Weight'] == G.edges[e]['Predict']:\n",
    "            if G.edges[e]['Weight'] > 0:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if G.edges[e]['Predict'] > 0:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    \n",
    "    precision_pos = TP/(TP+FP)\n",
    "    recall_pos    = TP/(TP+FN)\n",
    "    precision_neg = TN/(TN+FN)\n",
    "    recall_neg    = TN/(TN+FP)\n",
    "    F_score_pos = (2*precision_pos*recall_pos/(precision_pos + recall_pos)) if precision_pos + recall_pos != 0 else 0\n",
    "    F_score_neg = (2*precision_neg*recall_neg/(precision_neg + recall_neg)) if precision_neg + recall_neg != 0 else 0\n",
    "    \n",
    "    if TP*TN*FP*FN == 0:\n",
    "        MCC = 0\n",
    "    else:\n",
    "        MCC = (TP*TN - FP*FN)/np.sqrt(float((TP+FP)*(TP+FN)*(TN+FP)*(TN+FP)))\n",
    "    \n",
    "    print(\"TP: %d\\nTN: %d\\nFP: %d\\nFN: %d\\n\"%(TP, TN, FP, FN))\n",
    "    print(\"Precision on positive: %.3f\"% precision_pos)\n",
    "    print(\"Recall on positive: %.3f\"% recall_pos)\n",
    "    print(\"Precision on negative: %.3f\"% precision_neg)\n",
    "    print(\"Recall on negative: %.3f\\n\"% recall_neg)\n",
    "    print(\"F1 score on positive: %.3f\"  % F_score_pos)\n",
    "    print(\"F1 score on negative: %.3f\\n\"% F_score_neg)\n",
    "    print(\"Accuracy: %.3f\"%((TP+TN)/(TP+TN+FP+FN)))\n",
    "    print(\"Matthews correlation coefficient: %.3f\" %MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First algorithm\n",
    "The first algorithm `average_predict` is the one we have described above. It will first calculate the mean of outgoing weights and ingoing weights for every nodes and store them as attributes `Source score` and `Target score`. Then, for every edges, it will compare the source node score (average outgoing weights) and target node score (average ingoing weights) and predict the sign as explained above. Note that this is not a real case of prediction as we also count the weight of the edge that we want to predict in the averages. This first algorithm is implemented to get a first impression of the results that we could get. Furthermore, it is much faster than the next agorithms so we will use this speed to find some parameters in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_predict(dataframe):\n",
    "    # Dataframe to Graph\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "    \n",
    "    # Set source and target nodes attribute (ingoing and outgoing averages)\n",
    "    for node in G.nodes:\n",
    "        out_edges_weight = [G.get_edge_data(*e)['Weight'] for e in G.out_edges(node)]\n",
    "        in_edges_weight  = [G.get_edge_data(*e)['Weight'] for e in G.in_edges(node)]\n",
    "        G.nodes[node][\"Source score\"] = np.mean(out_edges_weight) if len(out_edges_weight) > 0 else np.nan\n",
    "        G.nodes[node][\"Target score\"] = np.mean(in_edges_weight)  if len(in_edges_weight)  > 0 else np.nan\n",
    "\n",
    "    # Compare node attributes for each edges\n",
    "    for e in G.edges:\n",
    "        # Retrieve node attributes\n",
    "        s = G.nodes[e[0]]['Source score']\n",
    "        t = G.nodes[e[1]]['Target score']\n",
    "        if np.isnan(s) or np.isnan(t):\n",
    "            raise ValueError(\"nan sould not be there\")\n",
    "        \n",
    "        # Case where source and target weight averages have same signs\n",
    "        if s*t > 0:\n",
    "            # Both are positive\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            # Both are negative\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "        \n",
    "        # Case where source and target weight averages have opposite signs\n",
    "        elif s*t < 0:\n",
    "            if s > 0:\n",
    "                # Get the largest of the two averages (absolute value)\n",
    "                if s > abs(t):\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s < abs(t):\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                # Both are equal -> we guess\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "            else:\n",
    "                # Get the largest of the two averages (absolute value)\n",
    "                if abs(s) > t:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                elif abs(s) < t:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                # Both are equal -> we guess\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "                    \n",
    "        # Case where one of the two source and target weight averages is 0\n",
    "        else:\n",
    "            if s + t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s + t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "    \n",
    "    # Evaluation\n",
    "    weighted_average_evaluation(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 715933\n",
      "TN: 84634\n",
      "FP: 39071\n",
      "FN: 1734\n",
      "\n",
      "Precision on positive: 0.948\n",
      "Recall on positive: 0.998\n",
      "Precision on negative: 0.980\n",
      "Recall on negative: 0.684\n",
      "\n",
      "F1 score on positive: 0.972\n",
      "F1 score on negative: 0.806\n",
      "\n",
      "Accuracy: 0.952\n",
      "Matthews correlation coefficient: 0.665\n"
     ]
    }
   ],
   "source": [
    "average_predict(epinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 418871\n",
      "TN: 66632\n",
      "FP: 57498\n",
      "FN: 6201\n",
      "\n",
      "Precision on positive: 0.879\n",
      "Recall on positive: 0.985\n",
      "Precision on negative: 0.915\n",
      "Recall on negative: 0.537\n",
      "\n",
      "F1 score on positive: 0.929\n",
      "F1 score on negative: 0.677\n",
      "\n",
      "Accuracy: 0.884\n",
      "Matthews correlation coefficient: 0.493\n"
     ]
    }
   ],
   "source": [
    "average_predict(slashdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 81102\n",
      "TN: 8714\n",
      "FP: 13295\n",
      "FN: 636\n",
      "\n",
      "Precision on positive: 0.859\n",
      "Recall on positive: 0.992\n",
      "Precision on negative: 0.932\n",
      "Recall on negative: 0.396\n",
      "\n",
      "F1 score on positive: 0.921\n",
      "F1 score on negative: 0.556\n",
      "\n",
      "Accuracy: 0.866\n",
      "Matthews correlation coefficient: 0.361\n"
     ]
    }
   ],
   "source": [
    "average_predict(wikielec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "We can see that the accuracies of our predictions for all datasets are already surprisingly good. But. The problem with our datasets is that they contain a lot more positive edges than negative ones. So the average of weights will more often be positve because there are just more positive edges. If we exagerate the idea, it's just as if we put all weights to +1 so that, as the positive weights are dominant, the accuracy will be high. This is why we need a binary class evaluation method to also evaluate the negative weight predictions. This evaluation problem can easily be resolved if we look at the recall on negative evaluations and see that they are low compared to the other evaluations. Having a low recall on negative weights simply means that there are too much false positives which means that too many weights were predicted to be positive as they were in reality negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_predict(dataframe, alpha):\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "\n",
    "    for e in G.edges:\n",
    "        G.edges[e]['Modified Weight'] = (1-alpha) if G.edges[e]['Weight'] > 0 else -alpha\n",
    "\n",
    "    for node in G.nodes:\n",
    "        out_edges_weight = [G.get_edge_data(*e)['Modified Weight'] for e in G.out_edges(node)]\n",
    "        in_edges_weight  = [G.get_edge_data(*e)['Modified Weight'] for e in G.in_edges(node)]\n",
    "        G.nodes[node][\"Source score\"] = np.mean(out_edges_weight) if len(out_edges_weight) > 0 else np.nan\n",
    "        G.nodes[node][\"Target score\"] = np.mean(in_edges_weight)  if len(in_edges_weight)  > 0 else np.nan\n",
    "\n",
    "\n",
    "    for e in G.edges:\n",
    "        s = G.nodes[e[0]]['Source score']\n",
    "        t = G.nodes[e[1]]['Target score']\n",
    "        if np.isnan(s) or np.isnan(t):\n",
    "            raise ValueError(\"nan cannot exist\")\n",
    "\n",
    "        if s*t > 0:\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "\n",
    "        elif s*t < 0:\n",
    "            if s > 0:\n",
    "                if s > abs(t):\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s < abs(t):\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "            else:\n",
    "                if abs(s) > t:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                elif abs(s) < t:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "        else:\n",
    "            if s + t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s + t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "    weighted_average_evaluation(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 704151\n",
      "TN: 101583\n",
      "FP: 22122\n",
      "FN: 13516\n",
      "\n",
      "Precision on positive: 0.970\n",
      "Recall on positive: 0.981\n",
      "Precision on negative: 0.883\n",
      "Recall on negative: 0.821\n",
      "\n",
      "F1 score on positive: 0.975\n",
      "F1 score on negative: 0.851\n",
      "\n",
      "Accuracy: 0.958\n",
      "Youden's J statistic: 0.826\n"
     ]
    }
   ],
   "source": [
    "weighted_average_predict(epinions, 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 397500\n",
      "TN: 95929\n",
      "FP: 28201\n",
      "FN: 27572\n",
      "\n",
      "Precision on positive: 0.934\n",
      "Recall on positive: 0.935\n",
      "Precision on negative: 0.777\n",
      "Recall on negative: 0.773\n",
      "\n",
      "F1 score on positive: 0.934\n",
      "F1 score on negative: 0.775\n",
      "\n",
      "Accuracy: 0.898\n",
      "Youden's J statistic: 0.709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7092180790991987"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_average_predict(slashdot, 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 76660\n",
      "TN: 15677\n",
      "FP: 6332\n",
      "FN: 5078\n",
      "\n",
      "Precision on positive: 0.924\n",
      "Recall on positive: 0.938\n",
      "Precision on negative: 0.755\n",
      "Recall on negative: 0.712\n",
      "\n",
      "F1 score on positive: 0.931\n",
      "F1 score on negative: 0.733\n",
      "\n",
      "Accuracy: 0.890\n",
      "Youden's J statistic: 0.664\n"
     ]
    }
   ],
   "source": [
    "weighted_average_predict(wikielec, 0.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight on personnality/performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha = 0 finds the percentage of positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_new: 0.5697640145520472\n",
      "Delta: 0.019764014552047127 \n",
      "\n",
      "alpha_new: 0.5740852201160805\n",
      "Delta: 0.00432120556403337 \n",
      "\n",
      "alpha_new: 0.5748827121148449\n",
      "Delta: 0.0007974919987643325 \n",
      "\n",
      "alpha_new: 0.5750433621949559\n",
      "Delta: 0.00016065008011101334 \n",
      "\n",
      "alpha_new: 0.5750853057346298\n",
      "Delta: 4.1943539673905406e-05 \n",
      "\n",
      "0.8198333433391702\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "delta = np.inf\n",
    "alpha_prec = 0.5\n",
    "alpha = 0.55\n",
    "gamma = 0.6\n",
    "f = 1\n",
    "while delta > 1e-4:\n",
    "    f_prec = weighted_average_predict(epinions, alpha_prec)\n",
    "    f = weighted_average_predict(epinions, alpha)\n",
    "    alpha_new = alpha + gamma*(f-f_prec)\n",
    "    delta = abs(alpha_new - alpha)\n",
    "    alpha_prec = alpha\n",
    "    alpha = alpha_new\n",
    "    print(\"alpha_new:\",alpha_new)\n",
    "    print(\"Delta:\",delta,\"\\n\")\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvo_weighted_average_predict(dataframe, alpha):\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "    \n",
    "    for e in G.edges:\n",
    "        G.edges[e]['Modified Weight'] = (1-alpha) if G.edges[e]['Weight'] > 0 else -alpha\n",
    "\n",
    "    for e in G.edges:\n",
    "        out_edges_weight = [G.get_edge_data(*edge)['Modified Weight'] for edge in G.out_edges(e[0]) if edge != e]\n",
    "        in_edges_weight  = [G.get_edge_data(*edge)['Modified Weight'] for edge in G.in_edges(e[1])  if edge != e]\n",
    "        \n",
    "        len_out = len(out_edges_weight)\n",
    "        len_in  = len(in_edges_weight)\n",
    "        \n",
    "        if 0 == len_out == len_in:\n",
    "            G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif len_out == 0:\n",
    "            t = np.mean(in_edges_weight)\n",
    "            if t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                 G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif len_in == 0:\n",
    "            s = np.mean(out_edges_weight)\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                 G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        else:\n",
    "            s = np.mean(out_edges_weight)\n",
    "            t = np.mean(in_edges_weight)\n",
    "            if s*t > 0:\n",
    "                if s > 0:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "\n",
    "            elif s*t < 0:\n",
    "                if s > 0:\n",
    "                    if s > abs(t):\n",
    "                        G.edges[e][\"Predict\"] = 1\n",
    "                    elif s < abs(t):\n",
    "                        G.edges[e][\"Predict\"] = -1\n",
    "                    else:\n",
    "                        G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "                else:\n",
    "                    if abs(s) > t:\n",
    "                        G.edges[e][\"Predict\"] = -1\n",
    "                    elif abs(s) < t:\n",
    "                        G.edges[e][\"Predict\"] = 1\n",
    "                    else:\n",
    "                        G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "            else:\n",
    "                if s + t > 0:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s + t < 0:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "    weighted_average_evaluation(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 690224\n",
      "TN: 91555\n",
      "FP: 32150\n",
      "FN: 27443\n",
      "\n",
      "Precision on positive: 0.955\n",
      "Recall on positive: 0.962\n",
      "Precision on negative: 0.769\n",
      "Recall on negative: 0.740\n",
      "\n",
      "F1 score on positive: 0.959\n",
      "F1 score on negative: 0.754\n",
      "\n",
      "Accuracy: 0.929\n",
      "Youden's J statistic: 0.713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7130783643955632"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvo_weighted_average_predict(epinions, 0.64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 382272\n",
      "TN: 87730\n",
      "FP: 36400\n",
      "FN: 42800\n",
      "\n",
      "Precision on positive: 0.913\n",
      "Recall on positive: 0.899\n",
      "Precision on negative: 0.672\n",
      "Recall on negative: 0.707\n",
      "\n",
      "F1 score on positive: 0.906\n",
      "F1 score on negative: 0.689\n",
      "\n",
      "Accuracy: 0.856\n",
      "Youden's J statistic: 0.595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5951297599970591"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvo_weighted_average_predict(slashdot, 0.64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 74961\n",
      "TN: 15064\n",
      "FP: 6945\n",
      "FN: 6777\n",
      "\n",
      "Precision on positive: 0.915\n",
      "Recall on positive: 0.917\n",
      "Precision on negative: 0.690\n",
      "Recall on negative: 0.684\n",
      "\n",
      "F1 score on positive: 0.916\n",
      "F1 score on negative: 0.687\n",
      "\n",
      "Accuracy: 0.868\n",
      "Youden's J statistic: 0.603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6032168017639983"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvo_weighted_average_predict(wikielec, 0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpo_weighted_average_predict(dataframe, alpha, test_percent):\n",
    "    \n",
    "    df = dataframe.sample(round(test_percent*dataframe.shape[0])) \n",
    "\n",
    "    G = nx.from_pandas_edgelist(dataframe, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=[\"Weight\"], create_using=nx.DiGraph())\n",
    "    \n",
    "    G_unknown = nx.from_pandas_edgelist(df, source=\"Source\", target=\"Target\", \n",
    "                                edge_attr=None, create_using=nx.DiGraph())\n",
    "\n",
    "    for e in G.edges:\n",
    "        if e in G_unknown.edges:\n",
    "            G.edges[e]['Modified Weight'] = np.nan\n",
    "        else:\n",
    "            G.edges[e]['Modified Weight'] = (1-alpha) if G.edges[e]['Weight'] > 0 else -alpha\n",
    "        \n",
    "    for node in G_unknown.nodes:\n",
    "        out_edges_weight = [G.get_edge_data(*e)['Modified Weight'] for e in G.out_edges(node)]\n",
    "        in_edges_weight  = [G.get_edge_data(*e)['Modified Weight'] for e in G.in_edges(node)]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            G.nodes[node][\"Source score\"] = np.nanmean(out_edges_weight)\n",
    "            G.nodes[node][\"Target score\"] = np.nanmean(in_edges_weight)\n",
    "            \n",
    "    for e in G_unknown.edges:\n",
    "        s = G.nodes[e[0]]['Source score']\n",
    "        t = G.nodes[e[1]]['Target score']\n",
    "        if np.nan == s == t:\n",
    "            G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif s == np.nan:\n",
    "            if t > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif t < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        elif t == np.nan:\n",
    "            if s > 0:\n",
    "                G.edges[e][\"Predict\"] = 1\n",
    "            elif s < 0:\n",
    "                G.edges[e][\"Predict\"] = -1\n",
    "            else:\n",
    "                G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "        else:\n",
    "            if s*t > 0:\n",
    "                if s > 0:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "\n",
    "            elif s*t < 0:\n",
    "                if s > 0:\n",
    "                    if s > abs(t):\n",
    "                        G.edges[e][\"Predict\"] = 1\n",
    "                    elif s < abs(t):\n",
    "                        G.edges[e][\"Predict\"] = -1\n",
    "                    else:\n",
    "                        G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "                else:\n",
    "                    if abs(s) > t:\n",
    "                        G.edges[e][\"Predict\"] = -1\n",
    "                    elif abs(s) < t:\n",
    "                        G.edges[e][\"Predict\"] = 1\n",
    "                    else:\n",
    "                        G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "            else:\n",
    "                if s + t > 0:\n",
    "                    G.edges[e][\"Predict\"] = 1\n",
    "                elif s + t < 0:\n",
    "                    G.edges[e][\"Predict\"] = -1\n",
    "                else:\n",
    "                    G.edges[e][\"Predict\"] = (1 if random() < 0.5 else -1)\n",
    "\n",
    "    weighted_average_stats(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 99175\n",
      "TN: 13566\n",
      "FP: 4893\n",
      "FN: 8572\n",
      "\n",
      "Precision on positive: 0.953\n",
      "Recall on positive: 0.920\n",
      "Precision on negative: 0.613\n",
      "Recall on negative: 0.735\n",
      "\n",
      "F1 score on positive: 0.936\n",
      "F1 score on negative: 0.668\n",
      "\n",
      "Accuracy: 0.893\n",
      "Youden's J statistic: 0.605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6047556212713925"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpo_weighted_average_predict(epinions, 0.63, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 55617\n",
      "TN: 12430\n",
      "FP: 6136\n",
      "FN: 8197\n",
      "\n",
      "Precision on positive: 0.901\n",
      "Recall on positive: 0.872\n",
      "Precision on negative: 0.603\n",
      "Recall on negative: 0.670\n",
      "\n",
      "F1 score on positive: 0.886\n",
      "F1 score on negative: 0.634\n",
      "\n",
      "Accuracy: 0.826\n",
      "Youden's J statistic: 0.520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5201507080917165"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpo_weighted_average_predict(slashdot, 0.63, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 11286\n",
      "TN: 2183\n",
      "FP: 1119\n",
      "FN: 974\n",
      "\n",
      "Precision on positive: 0.910\n",
      "Recall on positive: 0.921\n",
      "Precision on negative: 0.691\n",
      "Recall on negative: 0.661\n",
      "\n",
      "F1 score on positive: 0.915\n",
      "F1 score on negative: 0.676\n",
      "\n",
      "Accuracy: 0.866\n",
      "Youden's J statistic: 0.591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5910989454070832"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpo_weighted_average_predict(wikielec, 0.66, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extension: use dates exponential"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
